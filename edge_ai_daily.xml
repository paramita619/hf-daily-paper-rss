<?xml version="1.0" encoding="iso-8859-1"?>
<rss version="2.0"><channel><title>ğŸš€ Ultimate AI Feed - Authority First, Signal Over Noise</title><link>https://github.com/paramita619/hf-daily-paper-rss</link><description>Top 10 daily: semantic analysis, smart dedup, authority-first, quality over quantity.</description><lastBuildDate>Wed, 18 Feb 2026 23:18:10 GMT</lastBuildDate><generator>PyRSS2Gen-1.1.0</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>[1] [å¤§V/æƒå¨] OpenAI pushes into higher education as India seeks to scale AI skills</title><link>https://techcrunch.com/2026/02/18/openai-pushes-into-higher-education-as-india-seeks-to-scale-ai-skills/</link><description>&lt;div style='font-family: sans-serif; padding: 10px;'&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“Š Score: 170&lt;/strong&gt; | Category: å¤§V/æƒå¨&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“¡ Source:&lt;/strong&gt; TechCrunch | Domain: techcrunch.com&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœ¨ Why selected:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Source:TechCrunch(+15)&lt;/li&gt;
&lt;li&gt;âœ“A-Domain:techcrunch.com(+30)&lt;/li&gt;
&lt;li&gt;â­A-Authority:openai(+70)&lt;/li&gt;
&lt;li&gt;âœ“Industry-Gate:pass(+20)&lt;/li&gt;
&lt;li&gt;real_release&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“„ Summary:&lt;/strong&gt; OpenAI says its India education partnerships aim to reach more than 100,000 students, faculty, and staff over the next year....&lt;/p&gt;
&lt;/div&gt;</description><pubDate>Wed, 18 Feb 2026 23:18:10 GMT</pubDate></item><item><title>[2] [å¤§V/æƒå¨] Anthropic releases Sonnet 4.6</title><link>https://techcrunch.com/2026/02/17/anthropic-releases-sonnet-4-6/</link><description>&lt;div style='font-family: sans-serif; padding: 10px;'&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“Š Score: 153&lt;/strong&gt; | Category: å¤§V/æƒå¨&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“¡ Source:&lt;/strong&gt; TechCrunch | Domain: techcrunch.com&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœ¨ Why selected:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Source:TechCrunch(+15)&lt;/li&gt;
&lt;li&gt;âœ“A-Domain:techcrunch.com(+30)&lt;/li&gt;
&lt;li&gt;â­A-Authority:anthropic(+70)&lt;/li&gt;
&lt;li&gt;âœ“Industry-Gate:pass(+20)&lt;/li&gt;
&lt;li&gt;real_release&lt;/li&gt;
&lt;li&gt;TimeFactor:Ã—0.9&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“„ Summary:&lt;/strong&gt; Anthropic has released a new version of its midsized Sonnet model, keeping pace with the company's four-month update cycle....&lt;/p&gt;
&lt;/div&gt;</description><pubDate>Wed, 18 Feb 2026 23:18:10 GMT</pubDate></item><item><title>[3] [å¹³å°åº•åº§] Executorch: On-device AI across mobile, embedded and edge for PyTorch</title><link>https://github.com/pytorch/executorch</link><description>&lt;div style='font-family: sans-serif; padding: 10px;'&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“Š Score: 112&lt;/strong&gt; | Category: å¹³å°åº•åº§&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“¡ Source:&lt;/strong&gt; Hacker News | Domain: github.com&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœ¨ Why selected:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Source:Hacker News(+10)&lt;/li&gt;
&lt;li&gt;âœ“A-Domain:github.com(+30)&lt;/li&gt;
&lt;li&gt;L1-Tech:executorch(+40)&lt;/li&gt;
&lt;li&gt;L1-Tech:on-device(+40)&lt;/li&gt;
&lt;li&gt;L1-Tech:on-device ai(+40)&lt;/li&gt;
&lt;li&gt;TimeFactor:Ã—0.7&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;</description><pubDate>Wed, 18 Feb 2026 23:18:10 GMT</pubDate></item><item><title>[4] [æ¨¡å‹ç®—æ³•] ToaSt: Token Channel Selection and Structured Pruning for Efficient ViT</title><link>http://arxiv.org/abs/2602.15720v1</link><description>&lt;div style='font-family: sans-serif; padding: 10px;'&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“Š Score: 103&lt;/strong&gt; | Category: æ¨¡å‹ç®—æ³•&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“¡ Source:&lt;/strong&gt; AlphaXiv | Domain: arxiv.org&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœ¨ Why selected:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Source:AlphaXiv(+25)&lt;/li&gt;
&lt;li&gt;ğŸ”’S-Domain:arxiv.org(+50)&lt;/li&gt;
&lt;li&gt;L2-Tech:pruning(+25)&lt;/li&gt;
&lt;li&gt;L3-Tech:transformer(+15)&lt;/li&gt;
&lt;li&gt;TimeFactor:Ã—0.9&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“„ Summary:&lt;/strong&gt; Vision Transformers (ViTs) have achieved remarkable success across various vision tasks, yet their deployment is often hindered by prohibitive computational costs. While structured weight pruning and token compression have emerged as promising solutions, they suffer from prolonged retraining times and global propagation that creates optimization ch...&lt;/p&gt;
&lt;/div&gt;</description><pubDate>Wed, 18 Feb 2026 23:18:10 GMT</pubDate></item><item><title>[5] [æ¨¡å‹ç®—æ³•] Proactive Conversational Assistant for a Procedural Manual Task based on Audio and IMU</title><link>http://arxiv.org/abs/2602.15707v1</link><description>&lt;div style='font-family: sans-serif; padding: 10px;'&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“Š Score: 103&lt;/strong&gt; | Category: æ¨¡å‹ç®—æ³•&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“¡ Source:&lt;/strong&gt; AlphaXiv | Domain: arxiv.org&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœ¨ Why selected:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Source:AlphaXiv(+25)&lt;/li&gt;
&lt;li&gt;ğŸ”’S-Domain:arxiv.org(+50)&lt;/li&gt;
&lt;li&gt;L1-Tech:npu(+40)&lt;/li&gt;
&lt;li&gt;TimeFactor:Ã—0.9&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“„ Summary:&lt;/strong&gt; Real-time conversational assistants for procedural tasks often depend on video input, which can be computationally expensive and compromise user privacy. For the first time, we propose a real-time conversational assistant that provides comprehensive guidance for a procedural task using only lightweight privacy-preserving modalities such as audio an...&lt;/p&gt;
&lt;/div&gt;</description><pubDate>Wed, 18 Feb 2026 23:18:10 GMT</pubDate></item><item><title>[6] [æ¨¡å‹ç®—æ³•] jina-embeddings-v5-text: Task-Targeted Embedding Distillation</title><link>https://huggingface.co/papers/2602.15547</link><description>&lt;div style='font-family: sans-serif; padding: 10px;'&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“Š Score: 100&lt;/strong&gt; | Category: æ¨¡å‹ç®—æ³•&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“¡ Source:&lt;/strong&gt; HF Papers | Domain: huggingface.co&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœ¨ Why selected:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Source:HF Papers(+25)&lt;/li&gt;
&lt;li&gt;ğŸ”’S-Domain:huggingface.co(+50)&lt;/li&gt;
&lt;li&gt;L2-Tech:distillation(+25)&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;</description><pubDate>Wed, 18 Feb 2026 23:18:10 GMT</pubDate></item><item><title>[7] [å¹³å°åº•åº§] 9x MobileNet V2 size reduction with Quantization aware training</title><link>https://github.com/dakshjain-1616/Quantisation-Awareness-training-by-NEO</link><description>&lt;div style='font-family: sans-serif; padding: 10px;'&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“Š Score: 100&lt;/strong&gt; | Category: å¹³å°åº•åº§&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“¡ Source:&lt;/strong&gt; Hacker News | Domain: github.com&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœ¨ Why selected:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Source:Hacker News(+10)&lt;/li&gt;
&lt;li&gt;âœ“A-Domain:github.com(+30)&lt;/li&gt;
&lt;li&gt;L2-Tech:quantization(+25)&lt;/li&gt;
&lt;li&gt;edge_optimization&lt;/li&gt;
&lt;li&gt;TimeFactor:Ã—0.8&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;</description><pubDate>Wed, 18 Feb 2026 23:18:10 GMT</pubDate></item><item><title>[8] [æ¨¡å‹ç®—æ³•] Rethinking Metrics for Lexical Semantic Change Detection</title><link>http://arxiv.org/abs/2602.15716v1</link><description>&lt;div style='font-family: sans-serif; padding: 10px;'&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“Š Score: 99&lt;/strong&gt; | Category: æ¨¡å‹ç®—æ³•&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“¡ Source:&lt;/strong&gt; AlphaXiv | Domain: arxiv.org&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœ¨ Why selected:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Source:AlphaXiv(+25)&lt;/li&gt;
&lt;li&gt;ğŸ”’S-Domain:arxiv.org(+50)&lt;/li&gt;
&lt;li&gt;L3-Tech:rag(+15)&lt;/li&gt;
&lt;li&gt;âœ“Industry-Gate:pass(+20)&lt;/li&gt;
&lt;li&gt;TimeFactor:Ã—0.9&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“„ Summary:&lt;/strong&gt; Lexical semantic change detection (LSCD) increasingly relies on contextualised language model embeddings, yet most approaches still quantify change using a small set of semantic change metrics, primarily Average Pairwise Distance (APD) and cosine distance over word prototypes (PRT). We introduce Average Minimum Distance (AMD) and Symmetric Average ...&lt;/p&gt;
&lt;/div&gt;</description><pubDate>Wed, 18 Feb 2026 23:18:10 GMT</pubDate></item><item><title>[9] [è¡Œä¸šåŠ¨æ€] Show HN: MCGrad â€“ Fix ML Calibration in Subgroups (Open Source from Meta)</title><link>https://github.com/facebookincubator/MCGrad</link><description>&lt;div style='font-family: sans-serif; padding: 10px;'&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“Š Score: 95&lt;/strong&gt; | Category: è¡Œä¸šåŠ¨æ€&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“¡ Source:&lt;/strong&gt; Hacker News | Domain: github.com&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœ¨ Why selected:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Source:Hacker News(+10)&lt;/li&gt;
&lt;li&gt;âœ“A-Domain:github.com(+30)&lt;/li&gt;
&lt;li&gt;âœ“Industry-Gate:pass(+20)&lt;/li&gt;
&lt;li&gt;real_release&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;</description><pubDate>Wed, 18 Feb 2026 23:18:10 GMT</pubDate></item><item><title>[10] [å¹³å°åº•åº§] LlamaLib: A cross-platform C++/C# library for local LLMs based on llama.cpp</title><link>https://github.com/undreamai/LlamaLib</link><description>&lt;div style='font-family: sans-serif; padding: 10px;'&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“Š Score: 84&lt;/strong&gt; | Category: å¹³å°åº•åº§&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“¡ Source:&lt;/strong&gt; Hacker News | Domain: github.com&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœ¨ Why selected:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Source:Hacker News(+10)&lt;/li&gt;
&lt;li&gt;âœ“A-Domain:github.com(+30)&lt;/li&gt;
&lt;li&gt;L1-Tech:llama.cpp(+40)&lt;/li&gt;
&lt;li&gt;L1-Tech:local llm(+40)&lt;/li&gt;
&lt;li&gt;TimeFactor:Ã—0.7&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;</description><pubDate>Wed, 18 Feb 2026 23:18:10 GMT</pubDate></item></channel></rss>