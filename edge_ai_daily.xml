<?xml version="1.0" encoding="iso-8859-1"?>
<rss version="2.0"><channel><title>ğŸ§  Intelligent AI &amp; Tech Feed</title><link>https://github.com/paramita619/hf-daily-paper-rss</link><description>High-quality, authority-focused feed for AI research, edge computing, and technical breakthroughs. Powered by multi-dimensional scoring.</description><lastBuildDate>Thu, 29 Jan 2026 00:29:54 GMT</lastBuildDate><generator>PyRSS2Gen-1.1.0</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>[315] ğŸ”¬ é¡¶çº§ç ”ç©¶ | Anthropic, Apple, OpenAI CEOs condemn ICE violence, praise Trump</title><link>https://techcrunch.com/2026/01/28/anthropic-and-openai-ceos-condemn-ice-violence-praise-trump/</link><description>&lt;div style='font-family: Arial, sans-serif;'&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“Š Quality Score: 315&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“‚ Category:&lt;/strong&gt; ğŸ”¬ é¡¶çº§ç ”ç©¶&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ” Source:&lt;/strong&gt; TechCrunch&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœ¨ Why selected:&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;
&lt;li&gt;Source base: +60 (TechCrunch)&lt;/li&gt;
&lt;li&gt;Top Lab: Openai&lt;/li&gt;
&lt;li&gt;Top Lab: Anthropic&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;</description><pubDate>Thu, 29 Jan 2026 00:29:54 GMT</pubDate></item><item><title>[185] ğŸ”¬ é¡¶çº§ç ”ç©¶ | ServiceNow inks another AI partnership, this time with Anthropic</title><link>https://techcrunch.com/2026/01/28/servicenow-inks-another-ai-partnership-this-time-with-anthropic/</link><description>&lt;div style='font-family: Arial, sans-serif;'&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“Š Quality Score: 185&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“‚ Category:&lt;/strong&gt; ğŸ”¬ é¡¶çº§ç ”ç©¶&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ” Source:&lt;/strong&gt; TechCrunch&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœ¨ Why selected:&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;
&lt;li&gt;Source base: +60 (TechCrunch)&lt;/li&gt;
&lt;li&gt;Top Lab: Anthropic&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;</description><pubDate>Thu, 29 Jan 2026 00:29:54 GMT</pubDate></item><item><title>[175] ğŸ”¬ é¡¶çº§ç ”ç©¶ | Opinion: Why did Apple ditch OpenAI for Google</title><link>https://www.crnasia.com/news/2026/artificial-intelligence/apple-ditches-openai-for-google</link><description>&lt;div style='font-family: Arial, sans-serif;'&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“Š Quality Score: 175&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“‚ Category:&lt;/strong&gt; ğŸ”¬ é¡¶çº§ç ”ç©¶&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ” Source:&lt;/strong&gt; Hacker News&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœ¨ Why selected:&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;
&lt;li&gt;Source base: +40 (Hacker News)&lt;/li&gt;
&lt;li&gt;Top Lab: Openai&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;</description><pubDate>Thu, 29 Jan 2026 00:29:54 GMT</pubDate></item><item><title>[170] ğŸ§  æ¨¡å‹ç®—æ³• | Visual Generation Unlocks Human-Like Reasoning through Multimodal World Models</title><link>http://arxiv.org/abs/2601.19834v1</link><description>&lt;div style='font-family: Arial, sans-serif;'&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“Š Quality Score: 170&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“‚ Category:&lt;/strong&gt; ğŸ§  æ¨¡å‹ç®—æ³•&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ” Source:&lt;/strong&gt; AlphaXiv&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœï¸ Author:&lt;/strong&gt; Jialong Wu&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœ¨ Why selected:&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;
&lt;li&gt;Source base: +100 (AlphaXiv)&lt;/li&gt;
&lt;li&gt;Algorithm: chain-of-thought&lt;/li&gt;
&lt;li&gt;Algorithm: reasoning&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“„ Summary:&lt;/strong&gt; Humans construct internal world models and reason by manipulating the concepts within these models. Recent advances in AI, particularly chain-of-thought (CoT) reasoning, approximate such human cognitive abilities, where world models are believed to be embedded within large language models. Expert-le...&lt;/p&gt;
&lt;/div&gt;</description><pubDate>Thu, 29 Jan 2026 00:29:54 GMT</pubDate></item><item><title>[170] ğŸ§  æ¨¡å‹ç®—æ³• | When Iterative RAG Beats Ideal Evidence: A Diagnostic Study in Scientific Multi-hop Question Answering</title><link>http://arxiv.org/abs/2601.19827v1</link><description>&lt;div style='font-family: Arial, sans-serif;'&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“Š Quality Score: 170&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“‚ Category:&lt;/strong&gt; ğŸ§  æ¨¡å‹ç®—æ³•&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ” Source:&lt;/strong&gt; AlphaXiv&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœï¸ Author:&lt;/strong&gt; Mahdi Astaraki&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœ¨ Why selected:&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;
&lt;li&gt;Source base: +100 (AlphaXiv)&lt;/li&gt;
&lt;li&gt;Algorithm: reasoning&lt;/li&gt;
&lt;li&gt;Algorithm: rag&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“„ Summary:&lt;/strong&gt; Retrieval-Augmented Generation (RAG) extends large language models (LLMs) beyond parametric knowledge, yet it is unclear when iterative retrieval-reasoning loops meaningfully outperform static RAG, particularly in scientific domains with multi-hop reasoning, sparse domain knowledge, and heterogeneou...&lt;/p&gt;
&lt;/div&gt;</description><pubDate>Thu, 29 Jan 2026 00:29:54 GMT</pubDate></item><item><title>[150] âš¡ ç«¯ä¾§/åº•å±‚æŠ€æœ¯ | Reflective Translation: Improving Low-Resource Machine Translation via Structured Self-Reflection</title><link>http://arxiv.org/abs/2601.19871v1</link><description>&lt;div style='font-family: Arial, sans-serif;'&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“Š Quality Score: 150&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“‚ Category:&lt;/strong&gt; âš¡ ç«¯ä¾§/åº•å±‚æŠ€æœ¯&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ” Source:&lt;/strong&gt; AlphaXiv&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœï¸ Author:&lt;/strong&gt; Nicholas Cheng&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœ¨ Why selected:&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;
&lt;li&gt;Source base: +100 (AlphaXiv)&lt;/li&gt;
&lt;li&gt;Edge AI: tpu&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“„ Summary:&lt;/strong&gt; Low-resource languages such as isiZulu and isiXhosa face persistent challenges in machine translation due to limited parallel data and linguistic resources. Recent advances in large language models suggest that self-reflection, prompting a model to critique and revise its own outputs, can improve re...&lt;/p&gt;
&lt;/div&gt;</description><pubDate>Thu, 29 Jan 2026 00:29:54 GMT</pubDate></item><item><title>[145] âš¡ ç«¯ä¾§/åº•å±‚æŠ€æœ¯ | Revisiting Incremental Stochastic Majorization-Minimization Algorithms with Applications to Mixture of Experts</title><link>http://arxiv.org/abs/2601.19811v1</link><description>&lt;div style='font-family: Arial, sans-serif;'&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“Š Quality Score: 145&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“‚ Category:&lt;/strong&gt; âš¡ ç«¯ä¾§/åº•å±‚æŠ€æœ¯&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ” Source:&lt;/strong&gt; AlphaXiv&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœï¸ Author:&lt;/strong&gt; TrungKhang Tran&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœ¨ Why selected:&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;
&lt;li&gt;Source base: +100 (AlphaXiv)&lt;/li&gt;
&lt;li&gt;Infrastructure: mixture of experts&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“„ Summary:&lt;/strong&gt; Processing high-volume, streaming data is increasingly common in modern statistics and machine learning, where batch-mode algorithms are often impractical because they require repeated passes over the full dataset. This has motivated incremental stochastic estimation methods, including the increment...&lt;/p&gt;
&lt;/div&gt;</description><pubDate>Thu, 29 Jan 2026 00:29:54 GMT</pubDate></item><item><title>[140] ğŸ§  æ¨¡å‹ç®—æ³• | HARMONI: Multimodal Personalization of Multi-User Human-Robot Interactions with LLMs</title><link>http://arxiv.org/abs/2601.19839v1</link><description>&lt;div style='font-family: Arial, sans-serif;'&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“Š Quality Score: 140&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“‚ Category:&lt;/strong&gt; ğŸ§  æ¨¡å‹ç®—æ³•&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ” Source:&lt;/strong&gt; AlphaXiv&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœï¸ Author:&lt;/strong&gt; Jeanne MalÃ©cot&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœ¨ Why selected:&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;
&lt;li&gt;Source base: +100 (AlphaXiv)&lt;/li&gt;
&lt;li&gt;Algorithm: rag&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“„ Summary:&lt;/strong&gt; Existing human-robot interaction systems often lack mechanisms for sustained personalization and dynamic adaptation in multi-user environments, limiting their effectiveness in real-world deployments. We present HARMONI, a multimodal personalization framework that leverages large language models to e...&lt;/p&gt;
&lt;/div&gt;</description><pubDate>Thu, 29 Jan 2026 00:29:54 GMT</pubDate></item><item><title>[140] âš¡ ç«¯ä¾§/åº•å±‚æŠ€æœ¯ | Show HN: Free On-Device AI SDK to Run PyTorch on Mobile NPUs (Open Source)</title><link>https://github.com/zetic-ai/ZETIC_MLange_apps</link><description>&lt;div style='font-family: Arial, sans-serif;'&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“Š Quality Score: 140&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“‚ Category:&lt;/strong&gt; âš¡ ç«¯ä¾§/åº•å±‚æŠ€æœ¯&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ” Source:&lt;/strong&gt; Hacker News&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœ¨ Why selected:&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;
&lt;li&gt;Source base: +40 (Hacker News)&lt;/li&gt;
&lt;li&gt;Edge AI: on-device ai&lt;/li&gt;
&lt;li&gt;Edge AI: npu&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;</description><pubDate>Thu, 29 Jan 2026 00:29:54 GMT</pubDate></item><item><title>[140] ğŸ“ æƒå¨å‘å£° | Mark Zuckerberg says a future without smart glasses is â€˜hard to imagineâ€™</title><link>https://techcrunch.com/2026/01/28/mark-zuckerberg-future-smart-glasses/</link><description>&lt;div style='font-family: Arial, sans-serif;'&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“Š Quality Score: 140&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“‚ Category:&lt;/strong&gt; ğŸ“ æƒå¨å‘å£°&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ” Source:&lt;/strong&gt; TechCrunch&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœ¨ Why selected:&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;
&lt;li&gt;Source base: +60 (TechCrunch)&lt;/li&gt;
&lt;li&gt;Leader: Mark Zuckerberg (Meta CEO)&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;</description><pubDate>Thu, 29 Jan 2026 00:29:54 GMT</pubDate></item><item><title>[140] ğŸ“ æƒå¨å‘å£° | Tesla to invest $2B in Elon Muskâ€™s xAI</title><link>https://techcrunch.com/2026/01/28/tesla-invested-2b-in-elon-musks-xai/</link><description>&lt;div style='font-family: Arial, sans-serif;'&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“Š Quality Score: 140&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“‚ Category:&lt;/strong&gt; ğŸ“ æƒå¨å‘å£°&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ” Source:&lt;/strong&gt; TechCrunch&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœ¨ Why selected:&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;
&lt;li&gt;Source base: +60 (TechCrunch)&lt;/li&gt;
&lt;li&gt;Leader: Elon Musk (xAI CEO)&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;</description><pubDate>Thu, 29 Jan 2026 00:29:54 GMT</pubDate></item><item><title>[140] ğŸ“ æƒå¨å‘å£° | Elon Musk teases a new image-labeling system for Xâ€¦ we think?</title><link>https://techcrunch.com/2026/01/28/elon-musk-teases-a-new-image-labeling-system-for-xwe-think/</link><description>&lt;div style='font-family: Arial, sans-serif;'&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“Š Quality Score: 140&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“‚ Category:&lt;/strong&gt; ğŸ“ æƒå¨å‘å£°&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ” Source:&lt;/strong&gt; TechCrunch&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœ¨ Why selected:&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;
&lt;li&gt;Source base: +60 (TechCrunch)&lt;/li&gt;
&lt;li&gt;Leader: Elon Musk (xAI CEO)&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;</description><pubDate>Thu, 29 Jan 2026 00:29:54 GMT</pubDate></item><item><title>[135] ğŸ§  æ¨¡å‹ç®—æ³• | AdaReasoner: Dynamic Tool Orchestration for Iterative Visual Reasoning</title><link>https://huggingface.co/papers/2601.18631</link><description>&lt;div style='font-family: Arial, sans-serif;'&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“Š Quality Score: 135&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“‚ Category:&lt;/strong&gt; ğŸ§  æ¨¡å‹ç®—æ³•&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ” Source:&lt;/strong&gt; HF Papers&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœ¨ Why selected:&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;
&lt;li&gt;Source base: +100 (HF Papers)&lt;/li&gt;
&lt;li&gt;Algorithm: reasoning&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;</description><pubDate>Thu, 29 Jan 2026 00:29:54 GMT</pubDate></item><item><title>[135] ğŸ§  æ¨¡å‹ç®—æ³• | A Pragmatic VLA Foundation Model</title><link>https://huggingface.co/papers/2601.18692</link><description>&lt;div style='font-family: Arial, sans-serif;'&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“Š Quality Score: 135&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“‚ Category:&lt;/strong&gt; ğŸ§  æ¨¡å‹ç®—æ³•&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ” Source:&lt;/strong&gt; HF Papers&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœ¨ Why selected:&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;
&lt;li&gt;Source base: +100 (HF Papers)&lt;/li&gt;
&lt;li&gt;Algorithm: rag&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;</description><pubDate>Thu, 29 Jan 2026 00:29:54 GMT</pubDate></item><item><title>[135] ğŸ§  æ¨¡å‹ç®—æ³• | Visual Generation Unlocks Human-Like Reasoning through Multimodal World Models</title><link>https://huggingface.co/papers/2601.19834</link><description>&lt;div style='font-family: Arial, sans-serif;'&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“Š Quality Score: 135&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“‚ Category:&lt;/strong&gt; ğŸ§  æ¨¡å‹ç®—æ³•&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ” Source:&lt;/strong&gt; HF Papers&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœ¨ Why selected:&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;
&lt;li&gt;Source base: +100 (HF Papers)&lt;/li&gt;
&lt;li&gt;Algorithm: reasoning&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;</description><pubDate>Thu, 29 Jan 2026 00:29:54 GMT</pubDate></item><item><title>[135] ğŸ§  æ¨¡å‹ç®—æ³• | FABLE: Forest-Based Adaptive Bi-Path LLM-Enhanced Retrieval for Multi-Document Reasoning</title><link>https://huggingface.co/papers/2601.18116</link><description>&lt;div style='font-family: Arial, sans-serif;'&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“Š Quality Score: 135&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“‚ Category:&lt;/strong&gt; ğŸ§  æ¨¡å‹ç®—æ³•&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ” Source:&lt;/strong&gt; HF Papers&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœ¨ Why selected:&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;
&lt;li&gt;Source base: +100 (HF Papers)&lt;/li&gt;
&lt;li&gt;Algorithm: reasoning&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;</description><pubDate>Thu, 29 Jan 2026 00:29:54 GMT</pubDate></item><item><title>[135] ğŸ§  æ¨¡å‹ç®—æ³• | HyperAlign: Hypernetwork for Efficient Test-Time Alignment of Diffusion Models</title><link>https://huggingface.co/papers/2601.15968</link><description>&lt;div style='font-family: Arial, sans-serif;'&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“Š Quality Score: 135&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“‚ Category:&lt;/strong&gt; ğŸ§  æ¨¡å‹ç®—æ³•&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ” Source:&lt;/strong&gt; HF Papers&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœï¸ Author:&lt;/strong&gt; Â· 3 authors&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœ¨ Why selected:&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;
&lt;li&gt;Source base: +100 (HF Papers)&lt;/li&gt;
&lt;li&gt;Algorithm: diffusion model&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;</description><pubDate>Thu, 29 Jan 2026 00:29:54 GMT</pubDate></item><item><title>[135] ğŸ§  æ¨¡å‹ç®—æ³• | Post-LayerNorm Is Back: Stable, ExpressivE, and Deep</title><link>http://arxiv.org/abs/2601.19895v1</link><description>&lt;div style='font-family: Arial, sans-serif;'&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“Š Quality Score: 135&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“‚ Category:&lt;/strong&gt; ğŸ§  æ¨¡å‹ç®—æ³•&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ” Source:&lt;/strong&gt; AlphaXiv&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœï¸ Author:&lt;/strong&gt; Chen Chen&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœ¨ Why selected:&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;
&lt;li&gt;Source base: +100 (AlphaXiv)&lt;/li&gt;
&lt;li&gt;Algorithm: transformer&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“„ Summary:&lt;/strong&gt; Large language model (LLM) scaling is hitting a wall. Widening models yields diminishing returns, and extending context length does not improve fundamental expressivity. In contrast, depth scaling offers theoretically superior expressivity, yet current Transformer architectures struggle to train rel...&lt;/p&gt;
&lt;/div&gt;</description><pubDate>Thu, 29 Jan 2026 00:29:54 GMT</pubDate></item><item><title>[135] ğŸ§  æ¨¡å‹ç®—æ³• | SONIC: Spectral Oriented Neural Invariant Convolutions</title><link>http://arxiv.org/abs/2601.19884v1</link><description>&lt;div style='font-family: Arial, sans-serif;'&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“Š Quality Score: 135&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“‚ Category:&lt;/strong&gt; ğŸ§  æ¨¡å‹ç®—æ³•&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ” Source:&lt;/strong&gt; AlphaXiv&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœï¸ Author:&lt;/strong&gt; Gijs Joppe Moens&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœ¨ Why selected:&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;
&lt;li&gt;Source base: +100 (AlphaXiv)&lt;/li&gt;
&lt;li&gt;Algorithm: transformer&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“„ Summary:&lt;/strong&gt; Convolutional Neural Networks (CNNs) rely on fixed-size kernels scanning local patches, which limits their ability to capture global context or long-range dependencies without very deep architectures. Vision Transformers (ViTs), in turn, provide global connectivity but lack spatial inductive bias, d...&lt;/p&gt;
&lt;/div&gt;</description><pubDate>Thu, 29 Jan 2026 00:29:54 GMT</pubDate></item><item><title>[135] ğŸ§  æ¨¡å‹ç®—æ³• | HexFormer: Hyperbolic Vision Transformer with Exponential Map Aggregation</title><link>http://arxiv.org/abs/2601.19849v1</link><description>&lt;div style='font-family: Arial, sans-serif;'&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“Š Quality Score: 135&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“‚ Category:&lt;/strong&gt; ğŸ§  æ¨¡å‹ç®—æ³•&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ” Source:&lt;/strong&gt; AlphaXiv&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœï¸ Author:&lt;/strong&gt; Haya Alyoussef&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœ¨ Why selected:&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;
&lt;li&gt;Source base: +100 (AlphaXiv)&lt;/li&gt;
&lt;li&gt;Algorithm: transformer&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“„ Summary:&lt;/strong&gt; Data across modalities such as images, text, and graphs often contains hierarchical and relational structures, which are challenging to model within Euclidean geometry. Hyperbolic geometry provides a natural framework for representing such structures. Building on this property, this work introduces ...&lt;/p&gt;
&lt;/div&gt;</description><pubDate>Thu, 29 Jan 2026 00:29:54 GMT</pubDate></item><item><title>[135] ğŸ§  æ¨¡å‹ç®—æ³• | Identifying and Transferring Reasoning-Critical Neurons: Improving LLM Inference Reliability via Activation Steering</title><link>http://arxiv.org/abs/2601.19847v1</link><description>&lt;div style='font-family: Arial, sans-serif;'&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“Š Quality Score: 135&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“‚ Category:&lt;/strong&gt; ğŸ§  æ¨¡å‹ç®—æ³•&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ” Source:&lt;/strong&gt; AlphaXiv&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœï¸ Author:&lt;/strong&gt; Fangan Dong&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœ¨ Why selected:&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;
&lt;li&gt;Source base: +100 (AlphaXiv)&lt;/li&gt;
&lt;li&gt;Algorithm: reasoning&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“„ Summary:&lt;/strong&gt; Despite the strong reasoning capabilities of recent large language models (LLMs), achieving reliable performance on challenging tasks often requires post-training or computationally expensive sampling strategies, limiting their practical efficiency. In this work, we first show that a small subset of...&lt;/p&gt;
&lt;/div&gt;</description><pubDate>Thu, 29 Jan 2026 00:29:54 GMT</pubDate></item><item><title>[135] ğŸ§  æ¨¡å‹ç®—æ³• | Query-Guided Spatial-Temporal-Frequency Interaction for Music Audio-Visual Question Answering</title><link>http://arxiv.org/abs/2601.19821v1</link><description>&lt;div style='font-family: Arial, sans-serif;'&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“Š Quality Score: 135&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“‚ Category:&lt;/strong&gt; ğŸ§  æ¨¡å‹ç®—æ³•&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ” Source:&lt;/strong&gt; AlphaXiv&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœï¸ Author:&lt;/strong&gt; Kun Li&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœ¨ Why selected:&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;
&lt;li&gt;Source base: +100 (AlphaXiv)&lt;/li&gt;
&lt;li&gt;Algorithm: reasoning&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“„ Summary:&lt;/strong&gt; Audio--Visual Question Answering (AVQA) is a challenging multimodal task that requires jointly reasoning over audio, visual, and textual information in a given video to answer natural language questions. Inspired by recent advances in Video QA, many existing AVQA approaches primarily focus on visual...&lt;/p&gt;
&lt;/div&gt;</description><pubDate>Thu, 29 Jan 2026 00:29:54 GMT</pubDate></item><item><title>[135] ğŸ§  æ¨¡å‹ç®—æ³• | Unsupervised Learning of Efficient Exploration: Pre-training Adaptive Policies via Self-Imposed Goals</title><link>http://arxiv.org/abs/2601.19810v1</link><description>&lt;div style='font-family: Arial, sans-serif;'&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“Š Quality Score: 135&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“‚ Category:&lt;/strong&gt; ğŸ§  æ¨¡å‹ç®—æ³•&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ” Source:&lt;/strong&gt; AlphaXiv&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœï¸ Author:&lt;/strong&gt; Octavio Pappalardo&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœ¨ Why selected:&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;
&lt;li&gt;Source base: +100 (AlphaXiv)&lt;/li&gt;
&lt;li&gt;Algorithm: lora&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“„ Summary:&lt;/strong&gt; Unsupervised pre-training can equip reinforcement learning agents with prior knowledge and accelerate learning in downstream tasks. A promising direction, grounded in human development, investigates agents that learn by setting and pursuing their own goals. The core challenge lies in how to effectiv...&lt;/p&gt;
&lt;/div&gt;</description><pubDate>Thu, 29 Jan 2026 00:29:54 GMT</pubDate></item><item><title>[105] ğŸ’» èŠ¯ç‰‡ç¡¬ä»¶ | Building a16zâ€™s Personal AI Workstation with four NVIDIA RTX 6000 Pro Blackwell Max-Q GPUs</title><link>https://a16z.com/building-a16zs-personal-ai-workstation-with-four-nvidia-rtx-6000-pro-blackwell-max-q-gpus/</link><description>&lt;div style='font-family: Arial, sans-serif;'&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“Š Quality Score: 105&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“‚ Category:&lt;/strong&gt; ğŸ’» èŠ¯ç‰‡ç¡¬ä»¶&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ” Source:&lt;/strong&gt; a16z&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœ¨ Why selected:&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;
&lt;li&gt;Source base: +80 (a16z)&lt;/li&gt;
&lt;li&gt;Hardware: 1 chips mentioned&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;</description><pubDate>Thu, 29 Jan 2026 00:29:54 GMT</pubDate></item><item><title>[95] âš¡ ç«¯ä¾§/åº•å±‚æŠ€æœ¯ | Show HN: I built a local macOS dictation app using Nvidia Parakeet and MLX</title><link>https://www.sayline.app/</link><description>&lt;div style='font-family: Arial, sans-serif;'&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“Š Quality Score: 95&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“‚ Category:&lt;/strong&gt; âš¡ ç«¯ä¾§/åº•å±‚æŠ€æœ¯&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ” Source:&lt;/strong&gt; Hacker News&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœ¨ Why selected:&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;
&lt;li&gt;Source base: +40 (Hacker News)&lt;/li&gt;
&lt;li&gt;Edge AI: mlx&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;</description><pubDate>Thu, 29 Jan 2026 00:29:54 GMT</pubDate></item><item><title>[90] âš¡ ç«¯ä¾§/åº•å±‚æŠ€æœ¯ | LiteRT: The Universal Framework for On-Device AI</title><link>https://developers.googleblog.com/litert-the-universal-framework-for-on-device-ai//</link><description>&lt;div style='font-family: Arial, sans-serif;'&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“Š Quality Score: 90&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“‚ Category:&lt;/strong&gt; âš¡ ç«¯ä¾§/åº•å±‚æŠ€æœ¯&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ” Source:&lt;/strong&gt; Hacker News&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœ¨ Why selected:&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;
&lt;li&gt;Source base: +40 (Hacker News)&lt;/li&gt;
&lt;li&gt;Edge AI: on-device ai&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;</description><pubDate>Thu, 29 Jan 2026 00:29:54 GMT</pubDate></item><item><title>[90] âš¡ ç«¯ä¾§/åº•å±‚æŠ€æœ¯ | Local Browser â€“ On-Device AI Web Automation</title><link>https://github.com/RunanywhereAI/on-device-browser-agent</link><description>&lt;div style='font-family: Arial, sans-serif;'&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“Š Quality Score: 90&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“‚ Category:&lt;/strong&gt; âš¡ ç«¯ä¾§/åº•å±‚æŠ€æœ¯&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ” Source:&lt;/strong&gt; Hacker News&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœ¨ Why selected:&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;
&lt;li&gt;Source base: +40 (Hacker News)&lt;/li&gt;
&lt;li&gt;Edge AI: on-device ai&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;</description><pubDate>Thu, 29 Jan 2026 00:29:54 GMT</pubDate></item><item><title>[90] âš¡ ç«¯ä¾§/åº•å±‚æŠ€æœ¯ | Removing branches from the hot path: A 60% speed-up for Product Quantization</title><link>https://twitter.com/etiennedi/status/2013304614183919617</link><description>&lt;div style='font-family: Arial, sans-serif;'&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“Š Quality Score: 90&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“‚ Category:&lt;/strong&gt; âš¡ ç«¯ä¾§/åº•å±‚æŠ€æœ¯&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ” Source:&lt;/strong&gt; Hacker News&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœ¨ Why selected:&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;
&lt;li&gt;Source base: +40 (Hacker News)&lt;/li&gt;
&lt;li&gt;Edge AI: quantization&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;</description><pubDate>Thu, 29 Jan 2026 00:29:54 GMT</pubDate></item><item><title>[90] âš¡ ç«¯ä¾§/åº•å±‚æŠ€æœ¯ | Quantization and distillation effects on code LLMs</title><link>https://arxiv.org/abs/2601.02563</link><description>&lt;div style='font-family: Arial, sans-serif;'&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“Š Quality Score: 90&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“‚ Category:&lt;/strong&gt; âš¡ ç«¯ä¾§/åº•å±‚æŠ€æœ¯&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ” Source:&lt;/strong&gt; Hacker News&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœ¨ Why selected:&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;
&lt;li&gt;Source base: +40 (Hacker News)&lt;/li&gt;
&lt;li&gt;Edge AI: quantization&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;</description><pubDate>Thu, 29 Jan 2026 00:29:54 GMT</pubDate></item><item><title>[90] âš¡ ç«¯ä¾§/åº•å±‚æŠ€æœ¯ | Show HN: P.ai.os â€“ A local, modular AI "operating" system for macOS (M4/MLX)</title><link>https://news.ycombinator.com/item?id=46785400</link><description>&lt;div style='font-family: Arial, sans-serif;'&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“Š Quality Score: 90&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“‚ Category:&lt;/strong&gt; âš¡ ç«¯ä¾§/åº•å±‚æŠ€æœ¯&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ” Source:&lt;/strong&gt; Hacker News&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœ¨ Why selected:&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;
&lt;li&gt;Source base: +40 (Hacker News)&lt;/li&gt;
&lt;li&gt;Edge AI: mlx&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;</description><pubDate>Thu, 29 Jan 2026 00:29:54 GMT</pubDate></item></channel></rss>