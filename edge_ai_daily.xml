<?xml version="1.0" encoding="iso-8859-1"?>
<rss version="2.0"><channel><title>ğŸš€ Ultimate AI Feed - Authority First, Signal Over Noise</title><link>https://github.com/paramita619/hf-daily-paper-rss</link><description>Top 10 daily: semantic analysis, smart dedup, authority-first, quality over quantity.</description><lastBuildDate>Thu, 29 Jan 2026 21:42:35 GMT</lastBuildDate><generator>PyRSS2Gen-1.1.0</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>[1] [å¤§V/æƒå¨] ServiceNow inks another AI partnership, this time with Anthropic</title><link>https://techcrunch.com/2026/01/28/servicenow-inks-another-ai-partnership-this-time-with-anthropic/</link><description>&lt;div style='font-family: sans-serif; padding: 10px;'&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“Š Score: 216&lt;/strong&gt; | Category: å¤§V/æƒå¨&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“¡ Source:&lt;/strong&gt; TechCrunch | Domain: techcrunch.com&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœ¨ Why selected:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Source:TechCrunch(+15)&lt;/li&gt;
&lt;li&gt;âœ“A-Domain:techcrunch.com(+30)&lt;/li&gt;
&lt;li&gt;â­A-Authority:anthropic(+70)&lt;/li&gt;
&lt;li&gt;â­A-Authority:openai(+70)&lt;/li&gt;
&lt;li&gt;âœ“Industry-Gate:pass(+20)&lt;/li&gt;
&lt;li&gt;real_release&lt;/li&gt;
&lt;li&gt;TimeFactor:Ã—0.9&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“„ Summary:&lt;/strong&gt; ServiceNow partners with Anthropic just a week after announcing a partnership with OpenAI as the company takes a multi-model approach....&lt;/p&gt;
&lt;/div&gt;</description><pubDate>Thu, 29 Jan 2026 21:42:35 GMT</pubDate></item><item><title>[2] [å¹³å°åº•åº§] Show HN: Free On-Device AI SDK to Run PyTorch on Mobile NPUs (Open Source)</title><link>https://github.com/zetic-ai/ZETIC_MLange_apps</link><description>&lt;div style='font-family: sans-serif; padding: 10px;'&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“Š Score: 184&lt;/strong&gt; | Category: å¹³å°åº•åº§&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“¡ Source:&lt;/strong&gt; Hacker News | Domain: github.com&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœ¨ Why selected:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Source:Hacker News(+10)&lt;/li&gt;
&lt;li&gt;âœ“A-Domain:github.com(+30)&lt;/li&gt;
&lt;li&gt;L1-Tech:on-device ai(+40)&lt;/li&gt;
&lt;li&gt;L1-Tech:npu(+40)&lt;/li&gt;
&lt;li&gt;L1-Tech:on-device(+40)&lt;/li&gt;
&lt;li&gt;opensource_tool&lt;/li&gt;
&lt;li&gt;TimeFactor:Ã—0.9&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;</description><pubDate>Thu, 29 Jan 2026 21:42:35 GMT</pubDate></item><item><title>[3] [æ¨¡å‹ç®—æ³•] FreeFix: Boosting 3D Gaussian Splatting via Fine-Tuning-Free Diffusion Models</title><link>http://arxiv.org/abs/2601.20857v1</link><description>&lt;div style='font-family: sans-serif; padding: 10px;'&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“Š Score: 130&lt;/strong&gt; | Category: æ¨¡å‹ç®—æ³•&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“¡ Source:&lt;/strong&gt; AlphaXiv | Domain: arxiv.org&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœ¨ Why selected:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Source:AlphaXiv(+25)&lt;/li&gt;
&lt;li&gt;ğŸ”’S-Domain:arxiv.org(+50)&lt;/li&gt;
&lt;li&gt;L1-Tech:npu(+40)&lt;/li&gt;
&lt;li&gt;L3-Tech:rag(+15)&lt;/li&gt;
&lt;li&gt;L3-Tech:diffusion(+15)&lt;/li&gt;
&lt;li&gt;TimeFactor:Ã—0.9&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“„ Summary:&lt;/strong&gt; Neural Radiance Fields and 3D Gaussian Splatting have advanced novel view synthesis, yet still rely on dense inputs and often degrade at extrapolated views. Recent approaches leverage generative models, such as diffusion models, to provide additional supervision, but face a trade-off between generalization and fidelity: fine-tuning diffusion models...&lt;/p&gt;
&lt;/div&gt;</description><pubDate>Thu, 29 Jan 2026 21:42:35 GMT</pubDate></item><item><title>[4] [æ¨¡å‹ç®—æ³•] Shallow-Ï€: Knowledge Distillation for Flow-based VLAs</title><link>https://huggingface.co/papers/2601.20262</link><description>&lt;div style='font-family: sans-serif; padding: 10px;'&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“Š Score: 125&lt;/strong&gt; | Category: æ¨¡å‹ç®—æ³•&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“¡ Source:&lt;/strong&gt; HF Papers | Domain: huggingface.co&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœ¨ Why selected:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Source:HF Papers(+25)&lt;/li&gt;
&lt;li&gt;ğŸ”’S-Domain:huggingface.co(+50)&lt;/li&gt;
&lt;li&gt;L2-Tech:distillation(+25)&lt;/li&gt;
&lt;li&gt;L2-Tech:knowledge distillation(+25)&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;</description><pubDate>Thu, 29 Jan 2026 21:42:35 GMT</pubDate></item><item><title>[5] [å¹³å°åº•åº§] Executorch: On-device AI across mobile, embedded and edge for PyTorch</title><link>https://github.com/pytorch/executorch</link><description>&lt;div style='font-family: sans-serif; padding: 10px;'&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“Š Score: 112&lt;/strong&gt; | Category: å¹³å°åº•åº§&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“¡ Source:&lt;/strong&gt; Hacker News | Domain: github.com&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœ¨ Why selected:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Source:Hacker News(+10)&lt;/li&gt;
&lt;li&gt;âœ“A-Domain:github.com(+30)&lt;/li&gt;
&lt;li&gt;L1-Tech:on-device ai(+40)&lt;/li&gt;
&lt;li&gt;L1-Tech:executorch(+40)&lt;/li&gt;
&lt;li&gt;L1-Tech:on-device(+40)&lt;/li&gt;
&lt;li&gt;TimeFactor:Ã—0.7&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;</description><pubDate>Thu, 29 Jan 2026 21:42:35 GMT</pubDate></item><item><title>[6] [æ¨¡å‹ç®—æ³•] Smoothing the Black-Box: Signed-Distance Supervision for Black-Box Model Copying</title><link>http://arxiv.org/abs/2601.20773v1</link><description>&lt;div style='font-family: sans-serif; padding: 10px;'&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“Š Score: 103&lt;/strong&gt; | Category: æ¨¡å‹ç®—æ³•&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“¡ Source:&lt;/strong&gt; AlphaXiv | Domain: arxiv.org&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœ¨ Why selected:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Source:AlphaXiv(+25)&lt;/li&gt;
&lt;li&gt;ğŸ”’S-Domain:arxiv.org(+50)&lt;/li&gt;
&lt;li&gt;L1-Tech:npu(+40)&lt;/li&gt;
&lt;li&gt;TimeFactor:Ã—0.9&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“„ Summary:&lt;/strong&gt; Deployed machine learning systems must continuously evolve as data, architectures, and regulations change, often without access to original training data or model internals. In such settings, black-box copying provides a practical refactoring mechanism, i.e. upgrading legacy models by learning replicas from input-output queries alone. When restrict...&lt;/p&gt;
&lt;/div&gt;</description><pubDate>Thu, 29 Jan 2026 21:42:35 GMT</pubDate></item><item><title>[7] [æ¨¡å‹ç®—æ³•] Reinforcement Learning via Self-Distillation</title><link>https://huggingface.co/papers/2601.20802</link><description>&lt;div style='font-family: sans-serif; padding: 10px;'&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“Š Score: 100&lt;/strong&gt; | Category: æ¨¡å‹ç®—æ³•&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“¡ Source:&lt;/strong&gt; HF Papers | Domain: huggingface.co&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœ¨ Why selected:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Source:HF Papers(+25)&lt;/li&gt;
&lt;li&gt;ğŸ”’S-Domain:huggingface.co(+50)&lt;/li&gt;
&lt;li&gt;L2-Tech:distillation(+25)&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;</description><pubDate>Thu, 29 Jan 2026 21:42:35 GMT</pubDate></item><item><title>[8] [å¹³å°åº•åº§] Local Browser â€“ On-Device AI Web Automation</title><link>https://github.com/RunanywhereAI/on-device-browser-agent</link><description>&lt;div style='font-family: sans-serif; padding: 10px;'&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“Š Score: 96&lt;/strong&gt; | Category: å¹³å°åº•åº§&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“¡ Source:&lt;/strong&gt; Hacker News | Domain: github.com&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœ¨ Why selected:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Source:Hacker News(+10)&lt;/li&gt;
&lt;li&gt;âœ“A-Domain:github.com(+30)&lt;/li&gt;
&lt;li&gt;L1-Tech:on-device ai(+40)&lt;/li&gt;
&lt;li&gt;L1-Tech:on-device(+40)&lt;/li&gt;
&lt;li&gt;TimeFactor:Ã—0.8&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;</description><pubDate>Thu, 29 Jan 2026 21:42:35 GMT</pubDate></item><item><title>[9] [è¡Œä¸šåŠ¨æ€] Tiny startup Arcee AI built a 400B-parameter open source LLM from scratch to best Metaâ€™s Llama</title><link>https://techcrunch.com/2026/01/28/tiny-startup-arcee-ai-built-a-400b-open-source-llm-from-scratch-to-best-metas-llama/</link><description>&lt;div style='font-family: sans-serif; padding: 10px;'&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“Š Score: 90&lt;/strong&gt; | Category: è¡Œä¸šåŠ¨æ€&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“¡ Source:&lt;/strong&gt; TechCrunch | Domain: techcrunch.com&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœ¨ Why selected:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Source:TechCrunch(+15)&lt;/li&gt;
&lt;li&gt;âœ“A-Domain:techcrunch.com(+30)&lt;/li&gt;
&lt;li&gt;âœ“Industry-Gate:pass(+20)&lt;/li&gt;
&lt;li&gt;real_release&lt;/li&gt;
&lt;li&gt;TimeFactor:Ã—0.9&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“„ Summary:&lt;/strong&gt; 30-person startup Arcee AI has released a 400B model called Trinity, which it says is one of the biggest open source foundation models from a U.S. company....&lt;/p&gt;
&lt;/div&gt;</description><pubDate>Thu, 29 Jan 2026 21:42:35 GMT</pubDate></item><item><title>[10] [è¡Œä¸šåŠ¨æ€] With Appleâ€™s new Creator Studio Pro, AI is a tool to aid creation, not replace it</title><link>https://techcrunch.com/2026/01/28/with-apples-new-creator-studio-pro-ai-is-a-tool-to-aid-creation-not-replace-it/</link><description>&lt;div style='font-family: sans-serif; padding: 10px;'&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“Š Score: 72&lt;/strong&gt; | Category: è¡Œä¸šåŠ¨æ€&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“¡ Source:&lt;/strong&gt; TechCrunch | Domain: techcrunch.com&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœ¨ Why selected:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Source:TechCrunch(+15)&lt;/li&gt;
&lt;li&gt;âœ“A-Domain:techcrunch.com(+30)&lt;/li&gt;
&lt;li&gt;L3-Tech:rag(+15)&lt;/li&gt;
&lt;li&gt;âœ“Industry-Gate:pass(+20)&lt;/li&gt;
&lt;li&gt;TimeFactor:Ã—0.9&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“„ Summary:&lt;/strong&gt; Appleâ€™s Creator Studio Pro leverages AI to help creators with tedious tasks â€” like finding clips or building slides â€” without trying to do the work for them....&lt;/p&gt;
&lt;/div&gt;</description><pubDate>Thu, 29 Jan 2026 21:42:35 GMT</pubDate></item></channel></rss>