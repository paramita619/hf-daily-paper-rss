<?xml version="1.0" encoding="iso-8859-1"?>
<rss version="2.0"><channel><title>ğŸš€ Ultimate AI Feed - Authority First, Signal Over Noise</title><link>https://github.com/paramita619/hf-daily-paper-rss</link><description>Top 10 daily: semantic analysis, smart dedup, authority-first, quality over quantity.</description><lastBuildDate>Sat, 14 Feb 2026 23:13:30 GMT</lastBuildDate><generator>PyRSS2Gen-1.1.0</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>[1] [å¤§V/æƒå¨] OpenAI removes access to sycophancy-prone GPT-4o model</title><link>https://techcrunch.com/2026/02/13/openai-removes-access-to-sycophancy-prone-gpt-4o-model/</link><description>&lt;div style='font-family: sans-serif; padding: 10px;'&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“Š Score: 153&lt;/strong&gt; | Category: å¤§V/æƒå¨&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“¡ Source:&lt;/strong&gt; TechCrunch | Domain: techcrunch.com&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœ¨ Why selected:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Source:TechCrunch(+15)&lt;/li&gt;
&lt;li&gt;âœ“A-Domain:techcrunch.com(+30)&lt;/li&gt;
&lt;li&gt;â­A-Authority:openai(+70)&lt;/li&gt;
&lt;li&gt;âœ“Industry-Gate:pass(+20)&lt;/li&gt;
&lt;li&gt;real_release&lt;/li&gt;
&lt;li&gt;TimeFactor:Ã—0.9&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“„ Summary:&lt;/strong&gt; The model is known for its overly sycophantic nature and its role in several lawsuits involving users' unhealthy relationships with the chatbot....&lt;/p&gt;
&lt;/div&gt;</description><pubDate>Sat, 14 Feb 2026 23:13:30 GMT</pubDate></item><item><title>[2] [å¤§V/æƒå¨] A new version of OpenAIâ€™s Codex is powered by a new dedicated chip</title><link>https://techcrunch.com/2026/02/12/a-new-version-of-openais-codex-is-powered-by-a-new-dedicated-chip/</link><description>&lt;div style='font-family: sans-serif; padding: 10px;'&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“Š Score: 136&lt;/strong&gt; | Category: å¤§V/æƒå¨&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“¡ Source:&lt;/strong&gt; TechCrunch | Domain: techcrunch.com&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœ¨ Why selected:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Source:TechCrunch(+15)&lt;/li&gt;
&lt;li&gt;âœ“A-Domain:techcrunch.com(+30)&lt;/li&gt;
&lt;li&gt;â­A-Authority:openai(+70)&lt;/li&gt;
&lt;li&gt;âœ“Industry-Gate:pass(+20)&lt;/li&gt;
&lt;li&gt;real_release&lt;/li&gt;
&lt;li&gt;TimeFactor:Ã—0.8&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“„ Summary:&lt;/strong&gt; OpenAI calls the new coding tool the "first milestone" in its relationship with the chipmaker....&lt;/p&gt;
&lt;/div&gt;</description><pubDate>Sat, 14 Feb 2026 23:13:30 GMT</pubDate></item><item><title>[3] [å¤§V/æƒå¨] Anthropic raises another $30B in Series G, with a new value of $380B</title><link>https://techcrunch.com/2026/02/12/anthropic-raises-another-30-billion-in-series-g-with-a-new-value-of-380-billion/</link><description>&lt;div style='font-family: sans-serif; padding: 10px;'&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“Š Score: 124&lt;/strong&gt; | Category: å¤§V/æƒå¨&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“¡ Source:&lt;/strong&gt; TechCrunch | Domain: techcrunch.com&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœ¨ Why selected:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Source:TechCrunch(+15)&lt;/li&gt;
&lt;li&gt;âœ“A-Domain:techcrunch.com(+30)&lt;/li&gt;
&lt;li&gt;â­A-Authority:anthropic(+70)&lt;/li&gt;
&lt;li&gt;â­A-Authority:openai(+70)&lt;/li&gt;
&lt;li&gt;âŒIndustry-Gate:fail(-30)&lt;/li&gt;
&lt;li&gt;TimeFactor:Ã—0.8&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“„ Summary:&lt;/strong&gt; The infusion of funding for the AI startup takes place as it is vying for customers and cultural attention with its competitor, OpenAI....&lt;/p&gt;
&lt;/div&gt;</description><pubDate>Sat, 14 Feb 2026 23:13:30 GMT</pubDate></item><item><title>[4] [æ¨¡å‹ç®—æ³•] The Devil Behind Moltbook: Anthropic Safety is Always Vanishing in Self-Evolving AI Societies</title><link>https://huggingface.co/papers/2602.09877</link><description>&lt;div style='font-family: sans-serif; padding: 10px;'&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“Š Score: 115&lt;/strong&gt; | Category: æ¨¡å‹ç®—æ³•&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“¡ Source:&lt;/strong&gt; HF Papers | Domain: huggingface.co&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœ¨ Why selected:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Source:HF Papers(+25)&lt;/li&gt;
&lt;li&gt;ğŸ”’S-Domain:huggingface.co(+50)&lt;/li&gt;
&lt;li&gt;â­A-Authority:anthropic(+70)&lt;/li&gt;
&lt;li&gt;âŒIndustry-Gate:fail(-30)&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;</description><pubDate>Sat, 14 Feb 2026 23:13:30 GMT</pubDate></item><item><title>[5] [æ¨¡å‹ç®—æ³•] T3D: Few-Step Diffusion Language Models via Trajectory Self-Distillation with Direct Discriminative Optimization</title><link>https://huggingface.co/papers/2602.12262</link><description>&lt;div style='font-family: sans-serif; padding: 10px;'&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“Š Score: 115&lt;/strong&gt; | Category: æ¨¡å‹ç®—æ³•&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“¡ Source:&lt;/strong&gt; HF Papers | Domain: huggingface.co&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœ¨ Why selected:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Source:HF Papers(+25)&lt;/li&gt;
&lt;li&gt;ğŸ”’S-Domain:huggingface.co(+50)&lt;/li&gt;
&lt;li&gt;L2-Tech:distillation(+25)&lt;/li&gt;
&lt;li&gt;L3-Tech:diffusion(+15)&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;</description><pubDate>Sat, 14 Feb 2026 23:13:30 GMT</pubDate></item><item><title>[6] [æ¨¡å‹ç®—æ³•] Amortized Molecular Optimization via Group Relative Policy Optimization</title><link>http://arxiv.org/abs/2602.12162v1</link><description>&lt;div style='font-family: sans-serif; padding: 10px;'&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“Š Score: 104&lt;/strong&gt; | Category: æ¨¡å‹ç®—æ³•&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“¡ Source:&lt;/strong&gt; AlphaXiv | Domain: arxiv.org&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœ¨ Why selected:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Source:AlphaXiv(+25)&lt;/li&gt;
&lt;li&gt;ğŸ”’S-Domain:arxiv.org(+50)&lt;/li&gt;
&lt;li&gt;L1-Tech:npu(+40)&lt;/li&gt;
&lt;li&gt;L3-Tech:rag(+15)&lt;/li&gt;
&lt;li&gt;TimeFactor:Ã—0.8&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“„ Summary:&lt;/strong&gt; Molecular design encompasses tasks ranging from de-novo design to structural alteration of given molecules or fragments. For the latter, state-of-the-art methods predominantly function as "Instance Optimizers'', expending significant compute restarting the search for every input structure. While model-based approaches theoretically offer amortized ...&lt;/p&gt;
&lt;/div&gt;</description><pubDate>Sat, 14 Feb 2026 23:13:30 GMT</pubDate></item><item><title>[7] [æ¨¡å‹ç®—æ³•] SafeNeuron: Neuron-Level Safety Alignment for Large Language Models</title><link>http://arxiv.org/abs/2602.12158v1</link><description>&lt;div style='font-family: sans-serif; padding: 10px;'&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“Š Score: 104&lt;/strong&gt; | Category: æ¨¡å‹ç®—æ³•&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“¡ Source:&lt;/strong&gt; AlphaXiv | Domain: arxiv.org&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœ¨ Why selected:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Source:AlphaXiv(+25)&lt;/li&gt;
&lt;li&gt;ğŸ”’S-Domain:arxiv.org(+50)&lt;/li&gt;
&lt;li&gt;âœ“Industry-Gate:pass(+20)&lt;/li&gt;
&lt;li&gt;real_release&lt;/li&gt;
&lt;li&gt;TimeFactor:Ã—0.8&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“„ Summary:&lt;/strong&gt; Large language models (LLMs) and multimodal LLMs are typically safety-aligned before release to prevent harmful content generation. However, recent studies show that safety behaviors are concentrated in a small subset of parameters, making alignment brittle and easily bypassed through neuron-level attacks. Moreover, most existing alignment methods ...&lt;/p&gt;
&lt;/div&gt;</description><pubDate>Sat, 14 Feb 2026 23:13:30 GMT</pubDate></item><item><title>[8] [å¹³å°åº•åº§] LlamaLib: A cross-platform C++/C# library for local LLMs based on llama.cpp</title><link>https://github.com/undreamai/LlamaLib</link><description>&lt;div style='font-family: sans-serif; padding: 10px;'&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“Š Score: 84&lt;/strong&gt; | Category: å¹³å°åº•åº§&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“¡ Source:&lt;/strong&gt; Hacker News | Domain: github.com&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœ¨ Why selected:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Source:Hacker News(+10)&lt;/li&gt;
&lt;li&gt;âœ“A-Domain:github.com(+30)&lt;/li&gt;
&lt;li&gt;L1-Tech:local llm(+40)&lt;/li&gt;
&lt;li&gt;L1-Tech:llama.cpp(+40)&lt;/li&gt;
&lt;li&gt;TimeFactor:Ã—0.7&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;</description><pubDate>Sat, 14 Feb 2026 23:13:30 GMT</pubDate></item><item><title>[9] [å¹³å°åº•åº§] LocalMind â€“ WebGPU and WebLLM in-browser local AI chat</title><link>https://github.com/ipattis/LocalMind</link><description>&lt;div style='font-family: sans-serif; padding: 10px;'&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“Š Score: 84&lt;/strong&gt; | Category: å¹³å°åº•åº§&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“¡ Source:&lt;/strong&gt; Hacker News | Domain: github.com&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœ¨ Why selected:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Source:Hacker News(+10)&lt;/li&gt;
&lt;li&gt;âœ“A-Domain:github.com(+30)&lt;/li&gt;
&lt;li&gt;L1-Tech:local ai(+40)&lt;/li&gt;
&lt;li&gt;L2-Tech:webgpu(+25)&lt;/li&gt;
&lt;li&gt;TimeFactor:Ã—0.8&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;</description><pubDate>Sat, 14 Feb 2026 23:13:30 GMT</pubDate></item><item><title>[10] [å¹³å°åº•åº§] SnapLLM: Switch between local LLM in under 1ms Multi-model&amp;-modal serving engine</title><link>https://github.com/snapllm/snapllm</link><description>&lt;div style='font-family: sans-serif; padding: 10px;'&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“Š Score: 80&lt;/strong&gt; | Category: å¹³å°åº•åº§&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ğŸ“¡ Source:&lt;/strong&gt; Hacker News | Domain: github.com&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;âœ¨ Why selected:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Source:Hacker News(+10)&lt;/li&gt;
&lt;li&gt;âœ“A-Domain:github.com(+30)&lt;/li&gt;
&lt;li&gt;L1-Tech:local llm(+40)&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;</description><pubDate>Sat, 14 Feb 2026 23:13:30 GMT</pubDate></item></channel></rss>