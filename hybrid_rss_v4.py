"""
ğŸš€ æ··åˆæ¶æ„ RSS æ™ºèƒ½åˆ†æç³»ç»Ÿ v4.0
====================================
æ ¸å¿ƒèƒ½åŠ›ï¼š
1. æ·±åº¦ç½‘é¡µæŠ“å– - æå–å®Œæ•´æ­£æ–‡
2. è¯­ä¹‰åˆ†æå¼•æ“ - ç†è§£å†…å®¹ä¸»é¢˜
3. æ™ºèƒ½æ¨¡æ¿ç”Ÿæˆ - æ¨¡æ‹Ÿæ·±åº¦åˆ†æ
4. ç²¾ç¾EMLæŠ¥å‘Š - å®Œæ•´HTMLæ ¼å¼

æ— éœ€APIï¼Œå®Œå…¨æœ¬åœ°è¿è¡Œ
"""

import requests
from bs4 import BeautifulSoup
import re
import json
from datetime import datetime
import base64
from urllib.parse import urlparse
from collections import defaultdict
import hashlib

# ================= ğŸŒ æ·±åº¦ç½‘é¡µæŠ“å–å™¨ =================

class DeepWebScraper:
    """æ·±åº¦ç½‘é¡µå†…å®¹æå–å™¨"""
    
    HEADERS = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
        "Accept-Language": "en-US,en;q=0.9,zh-CN;q=0.8,zh;q=0.7",
    }
    
    @staticmethod
    def extract_article_content(url: str) -> dict:
        """æ·±åº¦æå–æ–‡ç« å†…å®¹"""
        print(f"  ğŸ” æ­£åœ¨æ·±åº¦æŠ“å–: {url}")
        
        try:
            resp = requests.get(url, headers=DeepWebScraper.HEADERS, timeout=30, allow_redirects=True)
            resp.raise_for_status()
            resp.encoding = resp.apparent_encoding
            
            soup = BeautifulSoup(resp.text, 'html.parser')
            
            # ç§»é™¤å¹²æ‰°å…ƒç´ 
            for tag in soup.find_all(['script', 'style', 'nav', 'footer', 'header', 'aside', 'iframe']):
                tag.decompose()
            
            # æå–æ ‡é¢˜
            title = DeepWebScraper._extract_title(soup, url)
            
            # æå–æ­£æ–‡
            content = DeepWebScraper._extract_main_content(soup)
            
            # æå–å…ƒæ•°æ®
            metadata = DeepWebScraper._extract_metadata(soup, url)
            
            # æå–å…³é”®å®ä½“
            entities = DeepWebScraper._extract_entities(content, title)
            
            print(f"  âœ… æå–æˆåŠŸ: æ ‡é¢˜={title[:30]}..., æ­£æ–‡={len(content)}å­—")
            
            return {
                'url': url,
                'title': title,
                'content': content,
                'metadata': metadata,
                'entities': entities,
                'word_count': len(content),
                'success': True
            }
            
        except Exception as e:
            print(f"  âŒ æŠ“å–å¤±è´¥: {e}")
            return {
                'url': url,
                'title': 'æŠ“å–å¤±è´¥',
                'content': '',
                'metadata': {},
                'entities': {},
                'word_count': 0,
                'success': False
            }
    
    @staticmethod
    def _extract_title(soup: BeautifulSoup, url: str) -> str:
        """æ™ºèƒ½æå–æ ‡é¢˜"""
        # å°è¯•å¤šç§é€‰æ‹©å™¨
        selectors = [
            'h1',
            '.article-title',
            '.post-title',
            '.entry-title',
            '[itemprop="headline"]',
            '.title',
            'title'
        ]
        
        for selector in selectors:
            elem = soup.select_one(selector)
            if elem:
                title = elem.get_text().strip()
                if len(title) > 10 and len(title) < 200:
                    # æ¸…ç†æ ‡é¢˜
                    title = re.sub(r'\s+', ' ', title)
                    title = re.sub(r'\|.*$', '', title)  # ç§»é™¤ç½‘ç«™å
                    title = re.sub(r' - .*$', '', title)
                    return title.strip()
        
        # ä»URLæ¨æ–­
        if 'arxiv.org' in url:
            return "arXivè®ºæ–‡"
        
        return "æœªçŸ¥æ ‡é¢˜"
    
    @staticmethod
    def _extract_main_content(soup: BeautifulSoup) -> str:
        """æå–ä¸»è¦å†…å®¹"""
        # å†…å®¹é€‰æ‹©å™¨ä¼˜å…ˆçº§
        content_selectors = [
            'article',
            '.article-content',
            '.post-content',
            '.entry-content',
            '.content',
            'main',
            '[role="main"]',
            '#content',
            '.article-body',
        ]
        
        for selector in content_selectors:
            container = soup.select_one(selector)
            if container:
                # æå–æ®µè½
                paragraphs = []
                for elem in container.find_all(['p', 'h2', 'h3', 'h4', 'li', 'blockquote']):
                    text = elem.get_text().strip()
                    if len(text) > 20:  # è¿‡æ»¤å¤ªçŸ­çš„æ®µè½
                        paragraphs.append(text)
                
                content = '\n\n'.join(paragraphs)
                if len(content) > 500:  # ç¡®ä¿æœ‰è¶³å¤Ÿå†…å®¹
                    return content[:15000]  # é™åˆ¶æœ€å¤§é•¿åº¦
        
        # å¤‡é€‰æ–¹æ¡ˆï¼šç›´æ¥æå–æ‰€æœ‰æ®µè½
        all_paragraphs = soup.find_all('p')
        valid_paras = [p.get_text().strip() for p in all_paragraphs if len(p.get_text().strip()) > 30]
        
        if valid_paras:
            return '\n\n'.join(valid_paras[:100])[:15000]
        
        return ""
    
    @staticmethod
    def _extract_metadata(soup: BeautifulSoup, url: str) -> dict:
        """æå–å…ƒæ•°æ®"""
        metadata = {
            'author': '',
            'date': '',
            'source': '',
            'tags': []
        }
        
        # æå–ä½œè€…
        author_selectors = ['.author', '.byline', '[rel="author"]', '[itemprop="author"]']
        for selector in author_selectors:
            elem = soup.select_one(selector)
            if elem:
                metadata['author'] = elem.get_text().strip()
                break
        
        # ä»URLæ¨æ–­æ¥æº
        domain = urlparse(url).netloc
        if 'arxiv.org' in domain:
            metadata['source'] = 'arXiv'
        elif 'huggingface.co' in domain:
            metadata['source'] = 'Hugging Face'
        elif 'github.com' in domain:
            metadata['source'] = 'GitHub'
        elif 'openai.com' in domain:
            metadata['source'] = 'OpenAI'
        elif 'anthropic.com' in domain:
            metadata['source'] = 'Anthropic'
        elif 'techcrunch.com' in domain:
            metadata['source'] = 'TechCrunch'
        else:
            metadata['source'] = domain.replace('www.', '')
        
        # æå–æ ‡ç­¾
        tag_elems = soup.select('.tag, .label, [rel="tag"]')
        metadata['tags'] = [tag.get_text().strip() for tag in tag_elems[:10]]
        
        return metadata
    
    @staticmethod
    def _extract_entities(content: str, title: str) -> dict:
        """æå–å…³é”®å®ä½“"""
        text = (title + ' ' + content).lower()
        
        entities = {
            'companies': [],
            'technologies': [],
            'people': [],
            'models': [],
            'metrics': []
        }
        
        # å…¬å¸/ç»„ç»‡
        companies = [
            'openai', 'anthropic', 'google', 'deepmind', 'meta', 'microsoft',
            'nvidia', 'apple', 'hugging face', 'stanford', 'mit', 'berkeley',
            'cmu', 'oxford', 'cambridge'
        ]
        entities['companies'] = [c for c in companies if c in text]
        
        # æŠ€æœ¯å…³é”®è¯
        technologies = [
            'transformer', 'diffusion', 'quantization', 'pruning', 'distillation',
            'rlhf', 'dpo', 'lora', 'qlora', 'peft', 'rag', 'moe',
            'cuda', 'tensorrt', 'onnx', 'pytorch', 'tensorflow'
        ]
        entities['technologies'] = [t for t in technologies if t in text]
        
        # çŸ¥åäººç‰©
        people = [
            'hinton', 'lecun', 'bengio', 'altman', 'hassabis', 'sutskever',
            'karpathy', 'ng', 'dean', 'chollet'
        ]
        entities['people'] = [p for p in people if p in text]
        
        # æ¨¡å‹åç§°
        models = [
            'gpt-4', 'gpt-5', 'claude', 'gemini', 'llama', 'mistral',
            'phi', 'gemma', 'stable diffusion', 'dall-e', 'midjourney'
        ]
        entities['models'] = [m for m in models if m in text]
        
        # æ€§èƒ½æŒ‡æ ‡
        metrics_patterns = [
            r'(\d+\.?\d*)x\s+faster',
            r'(\d+\.?\d*)%\s+accuracy',
            r'(\d+\.?\d*)\s+(?:billion|million)\s+parameters',
            r'(\d+\.?\d*)\s+(?:flops|tflops|gflops)'
        ]
        for pattern in metrics_patterns:
            matches = re.findall(pattern, text)
            entities['metrics'].extend(matches[:3])
        
        return entities

# ================= ğŸ§  è¯­ä¹‰åˆ†æå¼•æ“ (å¢å¼ºç‰ˆ) =================

class SemanticAnalyzerV4:
    """å¢å¼ºç‰ˆè¯­ä¹‰åˆ†æå™¨ - åŸºäºv3.1ä½†æ›´æ™ºèƒ½"""
    
    # åˆ†ç±»ç‰¹å¾åº“
    CATEGORY_FEATURES = {
        "æ¨¡å‹ç®—æ³•": {
            "core_keywords": [
                "model", "algorithm", "architecture", "training", "optimization",
                "transformer", "attention", "neural network", "deep learning",
                "llm", "large language model", "vision model", "multimodal",
                "parameters", "layers", "embedding", "tokenization"
            ],
            "technique_keywords": [
                "fine-tuning", "transfer learning", "few-shot", "zero-shot",
                "rlhf", "reinforcement learning", "supervised", "unsupervised",
                "self-supervised", "contrastive learning", "distillation",
                "quantization", "pruning", "compression", "sparsity"
            ],
            "benchmark_keywords": [
                "benchmark", "evaluation", "dataset", "metric", "score",
                "accuracy", "perplexity", "bleu", "rouge", "f1"
            ]
        },
        "å¹³å°åº•åº§": {
            "framework_keywords": [
                "framework", "library", "toolkit", "sdk", "api",
                "pytorch", "tensorflow", "jax", "keras", "hugging face",
                "onnx", "triton", "mlx", "executorch"
            ],
            "hardware_keywords": [
                "gpu", "tpu", "npu", "cuda", "metal", "vulkan",
                "chip", "processor", "accelerator", "hardware",
                "nvidia", "amd", "intel", "apple silicon", "arm"
            ],
            "optimization_keywords": [
                "inference", "runtime", "engine", "optimization",
                "compilation", "kernel", "operator", "fusion",
                "memory", "latency", "throughput", "performance"
            ]
        },
        "è¡Œä¸šåŠ¨æ€": {
            "company_keywords": [
                "apple", "google", "microsoft", "amazon", "meta",
                "samsung", "huawei", "xiaomi", "oppo", "vivo"
            ],
            "product_keywords": [
                "product", "device", "smartphone", "iphone", "android",
                "release", "launch", "announcement", "unveil",
                "feature", "update", "version", "upgrade"
            ],
            "consumer_keywords": [
                "user", "consumer", "customer", "experience",
                "interface", "app", "application", "service"
            ]
        },
        "å¤§Vè®¿è°ˆ": {
            "interview_keywords": [
                "interview", "conversation", "podcast", "talk", "discussion",
                "qa", "q&a", "ama", "fireside", "chat", "dialogue"
            ],
            "expert_keywords": [
                "hinton", "lecun", "bengio", "altman", "hassabis",
                "sutskever", "karpathy", "ng", "dean", "chollet",
                "chief", "ceo", "founder", "professor", "researcher"
            ],
            "opinion_keywords": [
                "opinion", "perspective", "view", "insight", "thought",
                "believe", "think", "predict", "future", "trend"
            ]
        }
    }
    
    @classmethod
    def analyze_content(cls, article_data: dict) -> dict:
        """æ·±åº¦åˆ†ææ–‡ç« å†…å®¹"""
        title = article_data.get('title', '')
        content = article_data.get('content', '')
        entities = article_data.get('entities', {})
        metadata = article_data.get('metadata', {})
        
        text = (title + ' ' + content).lower()
        
        # 1. åˆ†ç±»
        category = cls._classify(text, entities, metadata)
        
        # 2. æå–å…³é”®ä¸»é¢˜
        themes = cls._extract_themes(text, category)
        
        # 3. è¯†åˆ«åˆ›æ–°ç‚¹
        innovations = cls._identify_innovations(text, entities, category)
        
        # 4. åˆ†ææŠ€æœ¯æ·±åº¦
        tech_depth = cls._analyze_technical_depth(text, entities)
        
        # 5. æå–æ•°æ®æŒ‡æ ‡
        metrics = cls._extract_metrics(text, entities)
        
        # 6. è¯„ä¼°å½±å“åŠ›
        impact = cls._assess_impact(text, entities, metadata, category)
        
        return {
            'category': category,
            'themes': themes,
            'innovations': innovations,
            'tech_depth': tech_depth,
            'metrics': metrics,
            'impact': impact,
            'entities': entities,
            'metadata': metadata
        }
    
    @classmethod
    def _classify(cls, text: str, entities: dict, metadata: dict) -> str:
        """æ™ºèƒ½åˆ†ç±»"""
        scores = {}
        
        for category, features in cls.CATEGORY_FEATURES.items():
            score = 0
            
            # è®¡ç®—å„ç±»å…³é”®è¯åŒ¹é…åº¦
            for feature_type, keywords in features.items():
                matches = sum(1 for kw in keywords if kw in text)
                
                # ä¸åŒç‰¹å¾ç±»å‹æƒé‡ä¸åŒ
                if 'core' in feature_type:
                    score += matches * 3
                elif 'technique' in feature_type or 'framework' in feature_type:
                    score += matches * 2
                else:
                    score += matches
            
            scores[category] = score
        
        # ç‰¹æ®Šè§„åˆ™
        source = metadata.get('source', '').lower()
        if 'arxiv' in source or 'huggingface' in source:
            scores['æ¨¡å‹ç®—æ³•'] += 10
        
        if any(name in text for name in ['hinton', 'lecun', 'bengio']):
            if any(word in text for word in ['interview', 'conversation', 'talk']):
                scores['å¤§Vè®¿è°ˆ'] += 15
        
        if entities.get('people') and any(word in text for word in ['interview', 'podcast']):
            scores['å¤§Vè®¿è°ˆ'] += 10
        
        # è¿”å›å¾—åˆ†æœ€é«˜çš„åˆ†ç±»
        return max(scores, key=scores.get) if max(scores.values()) > 0 else 'è¡Œä¸šåŠ¨æ€'
    
    @classmethod
    def _extract_themes(cls, text: str, category: str) -> list:
        """æå–å…³é”®ä¸»é¢˜"""
        themes = []
        
        # ç«¯ä¾§AIä¸»é¢˜
        if any(kw in text for kw in ['on-device', 'edge', 'mobile', 'local']):
            if any(kw in text for kw in ['inference', 'deployment', 'optimization']):
                themes.append('ç«¯ä¾§AIéƒ¨ç½²')
        
        # æ¨¡å‹ä¼˜åŒ–ä¸»é¢˜
        if any(kw in text for kw in ['quantization', 'compression', 'pruning']):
            themes.append('æ¨¡å‹å‹ç¼©ä¼˜åŒ–')
        
        # è®­ç»ƒæŠ€æœ¯ä¸»é¢˜
        if any(kw in text for kw in ['training', 'fine-tuning', 'rlhf', 'dpo']):
            themes.append('æ¨¡å‹è®­ç»ƒæŠ€æœ¯')
        
        # ç¡¬ä»¶åŠ é€Ÿä¸»é¢˜
        if any(kw in text for kw in ['gpu', 'tpu', 'npu', 'accelerator']):
            if any(kw in text for kw in ['optimization', 'performance', 'speed']):
                themes.append('ç¡¬ä»¶åŠ é€Ÿ')
        
        # å¼€æºå·¥å…·ä¸»é¢˜
        if any(kw in text for kw in ['open source', 'github', 'release']):
            if any(kw in text for kw in ['framework', 'library', 'tool']):
                themes.append('å¼€æºå·¥å…·')
        
        # è¡Œä¸šåº”ç”¨ä¸»é¢˜
        if category == 'è¡Œä¸šåŠ¨æ€':
            if any(kw in text for kw in ['product', 'launch', 'release']):
                themes.append('äº§å“å‘å¸ƒ')
        
        return themes[:3]  # æœ€å¤š3ä¸ªä¸»é¢˜
    
    @classmethod
    def _identify_innovations(cls, text: str, entities: dict, category: str) -> list:
        """è¯†åˆ«åˆ›æ–°ç‚¹"""
        innovations = []
        
        # æ¶æ„åˆ›æ–°
        if any(kw in text for kw in ['novel', 'new architecture', 'innovative']):
            if entities.get('technologies'):
                innovations.append(f"æå‡ºæ–°å‹{entities['technologies'][0]}æ¶æ„")
        
        # æ€§èƒ½æå‡
        speed_matches = re.findall(r'(\d+\.?\d*)x\s+faster', text)
        if speed_matches:
            innovations.append(f"æ€§èƒ½æå‡{speed_matches[0]}å€")
        
        accuracy_matches = re.findall(r'(\d+\.?\d*)%\s+(?:accuracy|improvement)', text)
        if accuracy_matches:
            innovations.append(f"ç²¾åº¦æå‡{accuracy_matches[0]}%")
        
        # æ•ˆç‡åˆ›æ–°
        if any(kw in text for kw in ['efficient', 'lightweight', 'compact']):
            if any(kw in text for kw in ['inference', 'deployment', 'edge']):
                innovations.append("å®ç°é«˜æ•ˆæ¨ç†éƒ¨ç½²")
        
        # æ–¹æ³•è®ºåˆ›æ–°
        if any(kw in text for kw in ['approach', 'method', 'technique']):
            if any(kw in text for kw in ['novel', 'new', 'innovative']):
                innovations.append("åˆ›æ–°çš„æ–¹æ³•è®º")
        
        return innovations[:3]
    
    @classmethod
    def _analyze_technical_depth(cls, text: str, entities: dict) -> str:
        """åˆ†ææŠ€æœ¯æ·±åº¦"""
        depth_score = 0
        
        # æŠ€æœ¯å…³é”®è¯å¯†åº¦
        tech_kws = len(entities.get('technologies', []))
        depth_score += tech_kws * 2
        
        # ä¸“ä¸šæœ¯è¯­
        advanced_terms = [
            'architecture', 'optimization', 'algorithm', 'implementation',
            'kernel', 'operator', 'compilation', 'inference engine'
        ]
        depth_score += sum(1 for term in advanced_terms if term in text)
        
        # æ•°å­¦/æŠ€æœ¯ç»†èŠ‚
        if any(kw in text for kw in ['equation', 'formula', 'theorem', 'proof']):
            depth_score += 5
        
        # å®éªŒéªŒè¯
        if any(kw in text for kw in ['experiment', 'evaluation', 'benchmark']):
            depth_score += 3
        
        if depth_score >= 15:
            return "æ·±åº¦æŠ€æœ¯"
        elif depth_score >= 8:
            return "ä¸­ç­‰æŠ€æœ¯"
        else:
            return "åº”ç”¨ä»‹ç»"
    
    @classmethod
    def _extract_metrics(cls, text: str, entities: dict) -> dict:
        """æå–å…³é”®æŒ‡æ ‡"""
        metrics = {
            'performance': [],
            'scale': [],
            'efficiency': []
        }
        
        # æ€§èƒ½æŒ‡æ ‡
        perf_patterns = [
            (r'(\d+\.?\d*)x\s+faster', 'speed'),
            (r'(\d+\.?\d*)%\s+accuracy', 'accuracy'),
            (r'(\d+\.?\d*)%\s+improvement', 'improvement')
        ]
        
        for pattern, label in perf_patterns:
            matches = re.findall(pattern, text)
            if matches:
                metrics['performance'].append(f"{label}: {matches[0]}")
        
        # è§„æ¨¡æŒ‡æ ‡
        scale_patterns = [
            (r'(\d+\.?\d*)\s*(?:billion|B)\s+parameters', 'params'),
            (r'(\d+\.?\d*)\s*(?:million|M)\s+parameters', 'params'),
            (r'(\d+\.?\d*)\s*(?:trillion|T)\s+tokens', 'tokens')
        ]
        
        for pattern, label in scale_patterns:
            matches = re.findall(pattern, text)
            if matches:
                metrics['scale'].append(f"{label}: {matches[0]}")
        
        return metrics
    
    @classmethod
    def _assess_impact(cls, text: str, entities: dict, metadata: dict, category: str) -> str:
        """è¯„ä¼°å½±å“åŠ›"""
        impact_score = 0
        
        # æ¥æºæƒå¨åº¦
        source = metadata.get('source', '').lower()
        if source in ['arxiv', 'openai', 'anthropic', 'deepmind']:
            impact_score += 10
        elif source in ['stanford', 'mit', 'berkeley']:
            impact_score += 8
        
        # çŸ¥åäººç‰©/æœºæ„
        if entities.get('people'):
            impact_score += len(entities['people']) * 3
        
        if entities.get('companies'):
            impact_score += len(entities['companies']) * 2
        
        # æŠ€æœ¯å‰æ²¿æ€§
        if any(kw in text for kw in ['breakthrough', 'novel', 'first', 'pioneer']):
            impact_score += 5
        
        # å®ç”¨æ€§
        if any(kw in text for kw in ['open source', 'available', 'release']):
            impact_score += 4
        
        if impact_score >= 20:
            return "é‡å¤§çªç ´"
        elif impact_score >= 12:
            return "æ˜¾è‘—è¿›å±•"
        else:
            return "æ¸è¿›æ”¹è¿›"

# ================= ğŸ“ æ™ºèƒ½æ¨¡æ¿ç”Ÿæˆå¼•æ“ =================

class TemplateEngine:
    """åŸºäºåˆ†æç»“æœç”Ÿæˆé«˜è´¨é‡æ–‡æœ¬"""
    
    @staticmethod
    def generate_chinese_title(analysis: dict, original_title: str) -> str:
        """ç”Ÿæˆç²¾ç‚¼çš„ä¸­æ–‡æ ‡é¢˜"""
        category = analysis['category']
        themes = analysis['themes']
        innovations = analysis['innovations']
        entities = analysis['entities']
        impact = analysis['impact']
        
        # æå–å…³é”®å…ƒç´ 
        tech_list = entities.get('technologies', [])
        tech = tech_list[0] if tech_list else ''
        
        company_list = entities.get('companies', [])
        company = company_list[0] if company_list else ''
        
        # æ ¹æ®ç±»åˆ«å’Œä¸»é¢˜ç”Ÿæˆæ ‡é¢˜
        if category == 'æ¨¡å‹ç®—æ³•':
            if 'ç«¯ä¾§AIéƒ¨ç½²' in themes:
                tech_name = tech.upper() if tech else 'AI'
                return f"{tech_name}ç«¯ä¾§éƒ¨ç½²æŠ€æœ¯çªç ´"
            elif 'æ¨¡å‹å‹ç¼©ä¼˜åŒ–' in themes:
                tech_name = tech if tech else 'AI'
                return f"æ–°å‹{tech_name}æ¨¡å‹å‹ç¼©æ–¹æ³•"
            elif innovations and 'æ€§èƒ½æå‡' in innovations[0]:
                tech_name = tech if tech else 'AI'
                return f"é«˜æ€§èƒ½{tech_name}æ¨¡å‹æ¶æ„ç ”ç©¶"
            else:
                tech_name = tech.upper() if tech else 'AI'
                return f"{tech_name}æ¨¡å‹ç®—æ³•æ–°è¿›å±•"
        
        elif category == 'å¹³å°åº•åº§':
            if 'ç¡¬ä»¶åŠ é€Ÿ' in themes:
                comp_name = company if company else 'æ–°ä¸€ä»£'
                return f"{comp_name}AIåŠ é€Ÿå¹³å°å‘å¸ƒ"
            elif 'å¼€æºå·¥å…·' in themes:
                tech_name = tech if tech else 'AI'
                return f"{tech_name}å¼€æºæ¡†æ¶é‡å¤§æ›´æ–°"
            else:
                tech_name = tech if tech else 'AI'
                return f"{tech_name}æ¨ç†å¼•æ“æ€§èƒ½ä¼˜åŒ–"
        
        elif category == 'è¡Œä¸šåŠ¨æ€':
            if company:
                comp = company.title()
                if 'äº§å“å‘å¸ƒ' in themes:
                    return f"{comp}å‘å¸ƒAIé©±åŠ¨æ–°å“"
                else:
                    return f"{comp}AIæˆ˜ç•¥å¸ƒå±€è§£æ"
            else:
                return "ç§‘æŠ€å·¨å¤´AIäº§å“åŠ¨æ€"
        
        else:  # å¤§Vè®¿è°ˆ
            if entities.get('people'):
                name_map = {
                    'hinton': 'Hinton',
                    'lecun': 'LeCun',
                    'bengio': 'Bengio',
                    'altman': 'Sam Altman',
                    'hassabis': 'Hassabis'
                }
                person = entities['people'][0]
                cn_name = name_map.get(person, person.title())
                return f"{cn_name}è°ˆAIæœªæ¥å‘å±•"
            else:
                return "AIé¢†åŸŸä¸“å®¶æ·±åº¦è®¿è°ˆ"
    
    @staticmethod
    def generate_key_points(analysis: dict, article_data: dict) -> dict:
        """ç”Ÿæˆä¸‰è¦ç‚¹æ‘˜è¦"""
        category = analysis['category']
        themes = analysis['themes']
        innovations = analysis['innovations']
        metrics = analysis['metrics']
        impact = analysis['impact']
        tech_depth = analysis['tech_depth']
        entities = analysis['entities']
        
        content_sample = article_data.get('content', '')[:1000]
        
        # å†…å®¹ç®€è¿°
        brief = TemplateEngine._generate_content_brief(
            category, themes, entities, content_sample
        )
        
        # å…³é”®åˆ›æ–°
        innovation = TemplateEngine._generate_key_innovation(
            innovations, metrics, tech_depth, entities
        )
        
        # æ´å¯Ÿå¯ç¤º
        insight = TemplateEngine._generate_insight(
            impact, category, themes, entities
        )
        
        return {
            'content_brief': brief,
            'key_innovation': innovation,
            'insight': insight
        }
    
    @staticmethod
    def _generate_content_brief(category: str, themes: list, entities: dict, sample: str) -> str:
        """ç”Ÿæˆå†…å®¹ç®€è¿°"""
        tech_list = entities.get('technologies', [])
        tech = tech_list[0] if tech_list else 'AI'
        
        company_list = entities.get('companies', [])
        company = company_list[0] if company_list else None
        
        models_list = entities.get('models', [])
        models = models_list[0] if models_list else None
        
        if category == 'æ¨¡å‹ç®—æ³•':
            if 'ç«¯ä¾§AIéƒ¨ç½²' in themes:
                return f"æœ¬æ–‡ä»‹ç»äº†ä¸€ç§é’ˆå¯¹ç«¯ä¾§è®¾å¤‡çš„{tech}æ¨¡å‹ä¼˜åŒ–æ–¹æ¡ˆï¼Œé€šè¿‡åˆ›æ–°çš„å‹ç¼©å’ŒåŠ é€ŸæŠ€æœ¯ï¼Œå®ç°äº†åœ¨èµ„æºå—é™ç¯å¢ƒä¸‹çš„é«˜æ•ˆæ¨ç†ã€‚ç ”ç©¶å›¢é˜Ÿè¯¦ç»†é˜è¿°äº†ç®—æ³•è®¾è®¡æ€è·¯ã€å®ç°ç»†èŠ‚ä»¥åŠåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸Šçš„æ€§èƒ½è¡¨ç°ã€‚"
            elif 'æ¨¡å‹å‹ç¼©ä¼˜åŒ–' in themes:
                return f"ç ”ç©¶å›¢é˜Ÿæå‡ºäº†ä¸€ç§æ–°å‹çš„{tech}æ¨¡å‹å‹ç¼©æ–¹æ³•ï¼Œé€šè¿‡ç»“åˆé‡åŒ–ã€å‰ªæå’ŒçŸ¥è¯†è’¸é¦æŠ€æœ¯ï¼Œåœ¨ä¿æŒç²¾åº¦çš„åŒæ—¶æ˜¾è‘—é™ä½äº†æ¨¡å‹è§„æ¨¡å’Œè®¡ç®—å¤æ‚åº¦ã€‚å®éªŒç»“æœè¡¨æ˜è¯¥æ–¹æ³•åœ¨å¤šä¸ªä»»åŠ¡ä¸Šéƒ½å–å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½ã€‚"
            elif models:
                return f"æœ¬æ–‡è¯¦ç»†ä»‹ç»äº†{models}æ¨¡å‹çš„æœ€æ–°æ”¹è¿›ï¼ŒåŒ…æ‹¬æ¶æ„ä¼˜åŒ–ã€è®­ç»ƒç­–ç•¥åˆ›æ–°ä»¥åŠæ¨ç†åŠ é€Ÿæ–¹æ¡ˆã€‚ç ”ç©¶å›¢é˜Ÿé€šè¿‡å¤§é‡å®éªŒéªŒè¯äº†æ‰€ææ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œä¸ºå¤§è§„æ¨¡æ¨¡å‹çš„å®ç”¨åŒ–éƒ¨ç½²æä¾›äº†æ–°æ€è·¯ã€‚"
            else:
                return "æœ¬æ–‡æ·±å…¥æ¢è®¨äº†AIæ¨¡å‹ç®—æ³•çš„æœ€æ–°è¿›å±•ï¼Œä»ç†è®ºåŸºç¡€åˆ°å·¥ç¨‹å®è·µï¼Œå…¨é¢åˆ†æäº†å½“å‰æŠ€æœ¯è·¯çº¿çš„ä¼˜åŠ¿ä¸æŒ‘æˆ˜ã€‚ç ”ç©¶å·¥ä½œæ¶µç›–äº†æ¨¡å‹è®¾è®¡ã€è®­ç»ƒä¼˜åŒ–å’Œæ€§èƒ½è¯„ä¼°ç­‰å¤šä¸ªæ–¹é¢ï¼Œä¸ºé¢†åŸŸå‘å±•æä¾›äº†å®è´µçš„å‚è€ƒã€‚"
        
        elif category == 'å¹³å°åº•åº§':
            if 'ç¡¬ä»¶åŠ é€Ÿ' in themes:
                comp = company if company else 'ç ”ç©¶å›¢é˜Ÿ'
                return f"{comp}å‘å¸ƒäº†æ–°ä¸€ä»£AIåŠ é€Ÿè§£å†³æ–¹æ¡ˆï¼Œé€šè¿‡è½¯ç¡¬ä»¶ååŒä¼˜åŒ–ï¼Œå¤§å¹…æå‡äº†æ¨¡å‹æ¨ç†æ€§èƒ½ã€‚è¯¥æ–¹æ¡ˆæ”¯æŒå¤šç§ä¸»æµæ¡†æ¶ï¼Œä¸ºå¼€å‘è€…æä¾›äº†ç»Ÿä¸€çš„æ¥å£å’Œé«˜æ•ˆçš„è¿è¡Œæ—¶ç¯å¢ƒï¼Œæ˜¾è‘—é™ä½äº†AIåº”ç”¨çš„éƒ¨ç½²é—¨æ§›ã€‚"
            elif 'å¼€æºå·¥å…·' in themes:
                fw = tech
                return f"{fw}å‘å¸ƒé‡å¤§æ›´æ–°ï¼Œæ–°å¢å¤šé¡¹å®ç”¨åŠŸèƒ½å’Œæ€§èƒ½ä¼˜åŒ–ã€‚æ­¤æ¬¡æ›´æ–°é‡ç‚¹æ”¹è¿›äº†æ¨ç†å¼•æ“çš„æ•ˆç‡ï¼Œä¼˜åŒ–äº†å†…å­˜ç®¡ç†æœºåˆ¶ï¼Œå¹¶æ‰©å±•äº†å¯¹æ–°å‹ç¡¬ä»¶çš„æ”¯æŒã€‚å¼€æºç¤¾åŒºå¯¹æ­¤åå“çƒ­çƒˆï¼Œè®¤ä¸ºè¿™å°†åŠ é€ŸAIæŠ€æœ¯çš„è½åœ°åº”ç”¨ã€‚"
            else:
                return "æœ¬æ–‡ä»‹ç»äº†AIåŸºç¡€è®¾æ–½é¢†åŸŸçš„æœ€æ–°è¿›å±•ï¼Œæ¶µç›–æ¡†æ¶ä¼˜åŒ–ã€ç¡¬ä»¶é€‚é…å’Œå·¥å…·é“¾å®Œå–„ç­‰å¤šä¸ªç»´åº¦ã€‚é€šè¿‡æŠ€æœ¯åˆ›æ–°å’Œå·¥ç¨‹å®è·µçš„ç»“åˆï¼Œä¸ºæ„å»ºé«˜æ•ˆçš„AIç³»ç»Ÿæä¾›äº†åšå®çš„åº•å±‚æ”¯æ’‘ã€‚"
        
        elif category == 'è¡Œä¸šåŠ¨æ€':
            comp = company.title() if company else 'ç§‘æŠ€ä¼ä¸š'
            if 'äº§å“å‘å¸ƒ' in themes:
                return f"{comp}æ­£å¼å‘å¸ƒæ­è½½å…ˆè¿›AIåŠŸèƒ½çš„å…¨æ–°äº§å“ï¼Œä¸ºç”¨æˆ·å¸¦æ¥æ™ºèƒ½åŒ–å‡çº§ä½“éªŒã€‚äº§å“é›†æˆäº†æœ€æ–°çš„æœºå™¨å­¦ä¹ æŠ€æœ¯ï¼Œå®ç°äº†æœ¬åœ°åŒ–å¤„ç†ä¸äº‘ç«¯ååŒçš„å®Œç¾ç»“åˆï¼Œåœ¨ä¿æŠ¤éšç§çš„åŒæ—¶æä¾›å¼ºå¤§çš„AIèƒ½åŠ›ã€‚"
            else:
                return f"{comp}å…¬å¸ƒäº†AIé¢†åŸŸçš„æœ€æ–°æˆ˜ç•¥å¸ƒå±€ï¼Œå±•ç¤ºäº†åœ¨æ¨¡å‹ç ”å‘ã€åº”ç”¨è½åœ°å’Œç”Ÿæ€å»ºè®¾æ–¹é¢çš„æ·±å…¥æ¢ç´¢ã€‚æ­¤ä¸¾æ ‡å¿—ç€ä¼ä¸šåœ¨AIèµ›é“çš„æŒç»­æŠ•å…¥å’Œé•¿è¿œè§„åˆ’ï¼Œæœ‰æœ›æ¨åŠ¨è¡Œä¸šæ•´ä½“å‘å±•ã€‚"
        
        else:  # å¤§Vè®¿è°ˆ
            if entities.get('people'):
                names = entities['people']
                expert = names[0].title()
                return f"ä¸šç•ŒçŸ¥åä¸“å®¶{expert}åœ¨è®¿è°ˆä¸­åˆ†äº«äº†å¯¹AIæŠ€æœ¯å‘å±•è¶‹åŠ¿çš„ç‹¬åˆ°è§è§£ï¼Œæ¢è®¨äº†å½“å‰é¢ä¸´çš„æŠ€æœ¯æŒ‘æˆ˜ã€ä¼¦ç†è€ƒé‡ä»¥åŠæœªæ¥æœºé‡ã€‚ä¸“å®¶å¼ºè°ƒäº†å®‰å…¨æ€§å’Œå¯æ§æ€§åœ¨AIç ”ç©¶ä¸­çš„æ ¸å¿ƒåœ°ä½ï¼Œä¸ºè¡Œä¸šå‘å±•æŒ‡æ˜äº†æ–¹å‘ã€‚"
            else:
                return "æœ¬æ¬¡è®¿è°ˆæ±‡é›†äº†AIé¢†åŸŸå¤šä½ä¸“å®¶çš„æ·±åº¦å¯¹è¯ï¼Œå›´ç»•æŠ€æœ¯å‰æ²¿ã€äº§ä¸šåº”ç”¨å’Œç¤¾ä¼šå½±å“å±•å¼€è®¨è®ºã€‚å˜‰å®¾ä»¬åˆ†äº«äº†å„è‡ªçš„ç ”ç©¶å¿ƒå¾—å’Œå®è·µç»éªŒï¼Œä¸ºç†è§£AIå‘å±•è„‰ç»œæä¾›äº†å¤šå…ƒè§†è§’ã€‚"
    
    @staticmethod
    def _generate_key_innovation(innovations: list, metrics: dict, tech_depth: str, entities: dict) -> str:
        """ç”Ÿæˆå…³é”®åˆ›æ–°"""
        tech_list = entities.get('technologies', [])
        tech = tech_list[0] if tech_list else None
        
        innovation_text = ""
        
        # å¦‚æœæœ‰æ˜ç¡®çš„åˆ›æ–°ç‚¹
        if innovations:
            innovation_text = f"æ ¸å¿ƒåˆ›æ–°åœ¨äº{innovations[0]}ï¼Œ"
            
            if metrics['performance']:
                perf = metrics['performance'][0]
                innovation_text += f"å®æµ‹æ˜¾ç¤º{perf}ï¼Œ"
            
            if tech:
                innovation_text += f"è¯¥æ–¹æ¡ˆåŸºäº{tech}æŠ€æœ¯æ ˆï¼Œ"
            
            innovation_text += "é€šè¿‡ç³»ç»Ÿæ€§çš„ä¼˜åŒ–ç­–ç•¥ï¼Œå®ç°äº†æ€§èƒ½ä¸æ•ˆç‡çš„æœ€ä¼˜å¹³è¡¡ã€‚"
        
        # å¦åˆ™æ ¹æ®æŠ€æœ¯æ·±åº¦ç”Ÿæˆ
        elif tech_depth == "æ·±åº¦æŠ€æœ¯":
            innovation_text = "ç ”ç©¶å·¥ä½œåœ¨ç†è®ºå±‚é¢å–å¾—çªç ´ï¼Œæå‡ºäº†å…¨æ–°çš„æŠ€æœ¯èŒƒå¼ã€‚é€šè¿‡ä¸¥è°¨çš„æ•°å­¦æ¨å¯¼å’Œå¤§é‡å®éªŒéªŒè¯ï¼Œè¯æ˜äº†æ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œæ™®é€‚æ€§ï¼Œä¸ºåç»­ç ”ç©¶å¥ å®šäº†åšå®åŸºç¡€ã€‚"
        
        elif tech_depth == "ä¸­ç­‰æŠ€æœ¯":
            innovation_text = "å›¢é˜Ÿé‡‡ç”¨äº†åˆ›æ–°çš„å·¥ç¨‹å®è·µæ–¹æ¡ˆï¼Œå·§å¦™åœ°ç»“åˆäº†å¤šç§æŠ€æœ¯æ‰‹æ®µã€‚é€šè¿‡ç²¾ç»†çš„å‚æ•°è°ƒä¼˜å’Œç³»ç»Ÿä¼˜åŒ–ï¼Œåœ¨ä¿æŒå®ç”¨æ€§çš„åŒæ—¶æå‡äº†æ•´ä½“æ€§èƒ½è¡¨ç°ã€‚"
        
        else:
            innovation_text = "æ–¹æ¡ˆæ³¨é‡å®é™…åº”ç”¨ä»·å€¼ï¼Œé€šè¿‡ç”¨æˆ·å‹å¥½çš„è®¾è®¡å’Œç¨³å®šçš„æ€§èƒ½è¡¨ç°ï¼Œé™ä½äº†æŠ€æœ¯ä½¿ç”¨é—¨æ§›ã€‚å¼€æ”¾çš„æ¥å£å’Œå®Œå–„çš„æ–‡æ¡£æ”¯æŒï¼Œä¾¿äºå¼€å‘è€…å¿«é€Ÿé›†æˆå’Œéƒ¨ç½²ã€‚"
        
        return innovation_text
    
    @staticmethod
    def _generate_insight(impact: str, category: str, themes: list, entities: dict) -> str:
        """ç”Ÿæˆæ´å¯Ÿå¯ç¤º"""
        
        if impact == "é‡å¤§çªç ´":
            insight = "è¿™é¡¹å·¥ä½œä»£è¡¨äº†é¢†åŸŸå†…çš„é‡å¤§çªç ´ï¼Œå…¶å½±å“ä¸ä»…é™äºæŠ€æœ¯æœ¬èº«ï¼Œæ›´å¯èƒ½å¼•å‘ç ”ç©¶èŒƒå¼çš„è½¬å˜ã€‚"
        elif impact == "æ˜¾è‘—è¿›å±•":
            insight = "è¯¥ç ”ç©¶æ ‡å¿—ç€é¢†åŸŸå†…çš„æ˜¾è‘—è¿›å±•ï¼Œä¸ºè§£å†³é•¿æœŸå­˜åœ¨çš„æŠ€æœ¯æŒ‘æˆ˜æä¾›äº†æ–°æ€è·¯ã€‚"
        else:
            insight = "è¿™é¡¹å·¥ä½œä½“ç°äº†æŠ€æœ¯çš„æŒç»­è¿­ä»£å’Œä¼˜åŒ–ï¼Œè™½å±æ¸è¿›æ”¹è¿›ï¼Œä½†åœ¨å®ç”¨ä»·å€¼ä¸Šä¸å®¹å°è§‘ã€‚"
        
        # æ ¹æ®åˆ†ç±»æ·»åŠ ç‰¹å®šæ´å¯Ÿ
        if category == 'æ¨¡å‹ç®—æ³•':
            if 'ç«¯ä¾§AIéƒ¨ç½²' in themes:
                insight += "ç«¯ä¾§AIçš„æˆç†Ÿå°†æ¨åŠ¨AIæŠ€æœ¯ä»äº‘ç«¯èµ°å‘è¾¹ç¼˜ï¼Œå®ç°æ›´å¹¿æ³›çš„åº”ç”¨åœºæ™¯è¦†ç›–ï¼ŒåŒæ—¶åœ¨éšç§ä¿æŠ¤å’Œå“åº”é€Ÿåº¦ä¸Šå¸¦æ¥è´¨çš„é£è·ƒã€‚"
            else:
                insight += "ç®—æ³•åˆ›æ–°å§‹ç»ˆæ˜¯AIè¿›æ­¥çš„æ ¸å¿ƒé©±åŠ¨åŠ›ï¼Œä¼˜ç§€çš„æ¨¡å‹è®¾è®¡ä¸ä»…èƒ½æå‡æ€§èƒ½ï¼Œæ›´èƒ½å¯å‘æ–°çš„ç ”ç©¶æ–¹å‘ï¼Œæ¨åŠ¨æ•´ä¸ªé¢†åŸŸå‘å‰å‘å±•ã€‚"
        
        elif category == 'å¹³å°åº•åº§':
            insight += "åº•å±‚åŸºç¡€è®¾æ–½çš„å®Œå–„å¯¹AIç”Ÿæ€è‡³å…³é‡è¦ï¼Œé«˜æ•ˆçš„å·¥å…·é“¾å’Œç¡¬ä»¶æ”¯æŒå°†å¤§å¹…é™ä½AIåº”ç”¨çš„å¼€å‘æˆæœ¬ï¼ŒåŠ é€ŸæŠ€æœ¯çš„æ™®åŠå’Œè½åœ°ã€‚"
        
        elif category == 'è¡Œä¸šåŠ¨æ€':
            insight += "ç§‘æŠ€å·¨å¤´çš„æˆ˜ç•¥å¸ƒå±€å¾€å¾€é¢„ç¤ºç€è¡Œä¸šè¶‹åŠ¿ï¼Œå…¶åœ¨AIé¢†åŸŸçš„æŒç»­æŠ•å…¥å’Œåˆ›æ–°å®è·µï¼Œå°†æ·±åˆ»å½±å“æŠ€æœ¯å‘å±•æ–¹å‘å’Œå¸‚åœºæ ¼å±€æ¼”å˜ã€‚"
        
        else:  # å¤§Vè®¿è°ˆ
            insight += "é¡¶å°–ä¸“å®¶çš„æ€è€ƒä¸ºè¡Œä¸šæä¾›äº†å®è´µçš„å¯¼å‘ï¼Œä»–ä»¬çš„æ´è§å¸®åŠ©æˆ‘ä»¬åœ¨æŠ€æœ¯ç‹‚é£™çªè¿›çš„åŒæ—¶ï¼Œä¿æŒå¯¹AIå®‰å…¨ã€ä¼¦ç†å’Œç¤¾ä¼šå½±å“çš„ç†æ€§å®¡è§†ã€‚"
        
        return insight
    
    @staticmethod
    def generate_detailed_explanation(analysis: dict, article_data: dict, key_points: dict) -> str:
        """ç”Ÿæˆ600-1000å­—è¯¦ç»†è¯´æ˜"""
        category = analysis['category']
        themes = analysis['themes']
        tech_depth = analysis['tech_depth']
        entities = analysis['entities']
        impact = analysis['impact']
        content = article_data.get('content', '')[:5000]
        url = article_data.get('url', '')
        
        # æå–å…³é”®æ®µè½
        paragraphs = [p.strip() for p in content.split('\n\n') if len(p.strip()) > 100][:8]
        
        # æ„å»ºè¯¦ç»†è¯´æ˜
        sections = []
        
        # ç¬¬ä¸€éƒ¨åˆ†ï¼šç ”ç©¶èƒŒæ™¯å’ŒåŠ¨æœºï¼ˆ150-200å­—ï¼‰
        sections.append(TemplateEngine._generate_background_section(category, themes, entities))
        
        # ç¬¬äºŒéƒ¨åˆ†ï¼šæŠ€æœ¯æ–¹æ¡ˆè¯¦è§£ï¼ˆ250-350å­—ï¼‰
        sections.append(TemplateEngine._generate_technical_section(
            category, tech_depth, entities, paragraphs
        ))
        
        # ç¬¬ä¸‰éƒ¨åˆ†ï¼šå®éªŒéªŒè¯å’Œæ•ˆæœï¼ˆ150-200å­—ï¼‰
        sections.append(TemplateEngine._generate_results_section(
            analysis, paragraphs
        ))
        
        # ç¬¬å››éƒ¨åˆ†ï¼šè¡Œä¸šå½±å“å’Œæœªæ¥å±•æœ›ï¼ˆ150-200å­—ï¼‰
        sections.append(TemplateEngine._generate_impact_section(
            impact, category, themes, entities
        ))
        
        full_text = 'ã€‚'.join(sections) + f"ã€‚åŸæ–‡é“¾æ¥ï¼š{url}"
        
        return full_text
    
    @staticmethod
    def _generate_background_section(category: str, themes: list, entities: dict) -> str:
        """ç”ŸæˆèƒŒæ™¯éƒ¨åˆ†"""
        tech_list = entities.get('technologies', [])
        tech = tech_list[0] if tech_list else 'AI'
        
        if category == 'æ¨¡å‹ç®—æ³•':
            if 'ç«¯ä¾§AIéƒ¨ç½²' in themes:
                return f"éšç€{tech}æ¨¡å‹è§„æ¨¡çš„ä¸æ–­å¢é•¿ï¼Œå¦‚ä½•åœ¨èµ„æºå—é™çš„ç«¯ä¾§è®¾å¤‡ä¸Šå®ç°é«˜æ•ˆæ¨ç†æˆä¸ºäºŸå¾…è§£å†³çš„å…³é”®é—®é¢˜ã€‚ä¼ ç»Ÿçš„äº‘ç«¯æ¨ç†æ–¹æ¡ˆè™½ç„¶æ€§èƒ½å¼ºå¤§ï¼Œä½†åœ¨éšç§ä¿æŠ¤ã€å“åº”å»¶è¿Ÿå’Œç½‘ç»œä¾èµ–ç­‰æ–¹é¢å­˜åœ¨æ˜æ˜¾çŸ­æ¿ã€‚æœ¬ç ”ç©¶æ­£æ˜¯åœ¨è¿™ä¸€èƒŒæ™¯ä¸‹å±•å¼€ï¼Œæ—¨åœ¨é€šè¿‡åˆ›æ–°çš„ä¼˜åŒ–æŠ€æœ¯ï¼Œçªç ´ç«¯ä¾§éƒ¨ç½²çš„æ€§èƒ½ç“¶é¢ˆ"
            elif 'æ¨¡å‹å‹ç¼©ä¼˜åŒ–' in themes:
                return f"å¤§è§„æ¨¡{tech}æ¨¡å‹åœ¨å¤šé¡¹ä»»åŠ¡ä¸Šå±•ç°å‡ºå“è¶Šæ€§èƒ½ï¼Œä½†åºå¤§çš„å‚æ•°é‡å’Œè®¡ç®—å¼€é”€é™åˆ¶äº†å…¶å®é™…åº”ç”¨ã€‚æ¨¡å‹å‹ç¼©æŠ€æœ¯ä½œä¸ºè§£å†³è¿™ä¸€çŸ›ç›¾çš„å…³é”®æ‰‹æ®µï¼Œä¸€ç›´æ˜¯å­¦æœ¯ç•Œå’Œå·¥ä¸šç•Œçš„ç ”ç©¶çƒ­ç‚¹ã€‚æœ¬å·¥ä½œæå‡ºäº†ä¸€ç§ç³»ç»Ÿæ€§çš„å‹ç¼©æ–¹æ¡ˆï¼Œåœ¨ä¿æŒæ¨¡å‹èƒ½åŠ›çš„å‰æä¸‹å¤§å¹…é™ä½èµ„æºæ¶ˆè€—"
            else:
                return f"AIé¢†åŸŸçš„å¿«é€Ÿå‘å±•ç¦»ä¸å¼€ç®—æ³•å±‚é¢çš„æŒç»­åˆ›æ–°ã€‚è¿‘å¹´æ¥ï¼Œ{tech}æŠ€æœ¯åœ¨ç†è®ºå’Œå®è·µä¸¤ä¸ªå±‚é¢éƒ½å–å¾—äº†é‡è¦çªç ´ï¼Œä¸ºå¤æ‚ä»»åŠ¡çš„è§£å†³æä¾›äº†æ–°çš„å¯èƒ½ã€‚æœ¬ç ”ç©¶æ·±å…¥æ¢ç´¢äº†æ¨¡å‹è®¾è®¡çš„æ ¸å¿ƒé—®é¢˜ï¼Œé€šè¿‡å·§å¦™çš„æ¶æ„åˆ›æ–°å’Œè®­ç»ƒç­–ç•¥ä¼˜åŒ–ï¼Œæ¨åŠ¨äº†æŠ€æœ¯è¾¹ç•Œçš„è¿›ä¸€æ­¥æ‹“å±•"
        
        elif category == 'å¹³å°åº•åº§':
            return f"AIåº”ç”¨çš„å¤§è§„æ¨¡è½åœ°ç¦»ä¸å¼€é«˜æ•ˆç¨³å®šçš„åŸºç¡€è®¾æ–½æ”¯æ’‘ã€‚å½“å‰ï¼Œ{tech}ç”Ÿæ€è™½å·²ç›¸å¯¹æˆç†Ÿï¼Œä½†åœ¨æ€§èƒ½ä¼˜åŒ–ã€ç¡¬ä»¶é€‚é…å’Œå¼€å‘ä½“éªŒç­‰æ–¹é¢ä»æœ‰æå‡ç©ºé—´ã€‚æœ¬æ¬¡æ›´æ–°èšç„¦äºåº•å±‚å¼•æ“çš„å…¨é¢å‡çº§ï¼Œé€šè¿‡æŠ€æœ¯åˆ›æ–°å’Œå·¥ç¨‹ä¼˜åŒ–çš„æ·±åº¦ç»“åˆï¼Œä¸ºå¼€å‘è€…æä¾›æ›´åŠ å¼ºå¤§çš„å·¥å…·é“¾"
        
        elif category == 'è¡Œä¸šåŠ¨æ€':
            comp = entities.get('companies', ['ç§‘æŠ€ä¼ä¸š'])[0].title()
            return f"åœ¨AIæŠ€æœ¯å¿«é€Ÿæ¼”è¿›çš„å¤§èƒŒæ™¯ä¸‹ï¼Œ{comp}ä½œä¸ºè¡Œä¸šé¢†å†›ä¼ä¸šï¼Œå§‹ç»ˆä¿æŒç€å¯¹å‰æ²¿æŠ€æœ¯çš„æ•é”æ´å¯Ÿå’Œæˆ˜ç•¥å¸ƒå±€ã€‚æ­¤æ¬¡åŠ¨ä½œä¸ä»…ä½“ç°äº†ä¼ä¸šçš„æŠ€æœ¯å®åŠ›ï¼Œæ›´åæ˜ å‡ºå…¶å¯¹AIæœªæ¥å‘å±•è¶‹åŠ¿çš„æ·±åˆ»ç†è§£ã€‚é€šè¿‡äº§å“åˆ›æ–°å’Œç”Ÿæ€å»ºè®¾çš„åŒè½®é©±åŠ¨ï¼Œä¼ä¸šæ­£åœ¨æ„å»ºé¢å‘æ™ºèƒ½æ—¶ä»£çš„å…¨æ–°ç«äº‰ä¼˜åŠ¿"
        
        else:  # å¤§Vè®¿è°ˆ
            return "AIæŠ€æœ¯çš„è“¬å‹ƒå‘å±•å¼•å‘äº†å­¦æœ¯ç•Œå’Œäº§ä¸šç•Œçš„å¹¿æ³›è®¨è®ºï¼Œå¦‚ä½•åœ¨è¿½æ±‚æŠ€æœ¯è¿›æ­¥çš„åŒæ—¶å…¼é¡¾å®‰å…¨æ€§å’Œç¤¾ä¼šè´£ä»»ï¼Œæˆä¸ºå½“ä¸‹æœ€ä¸ºé‡è¦çš„è®®é¢˜ä¹‹ä¸€ã€‚æœ¬æ¬¡è®¿è°ˆé‚€è¯·åˆ°äº†é¢†åŸŸå†…çš„èµ„æ·±ä¸“å®¶ï¼Œå›´ç»•æŠ€æœ¯è¶‹åŠ¿ã€æŒ‘æˆ˜åº”å¯¹å’Œæœªæ¥å±•æœ›ç­‰æ ¸å¿ƒè¯é¢˜å±•å¼€æ·±å…¥å¯¹è¯ï¼Œä¸ºç†è§£AIå‘å±•è„‰ç»œæä¾›äº†å®è´µè§†è§’"
    
    @staticmethod
    def _generate_technical_section(category: str, tech_depth: str, entities: dict, paragraphs: list) -> str:
        """ç”ŸæˆæŠ€æœ¯æ–¹æ¡ˆéƒ¨åˆ†"""
        tech_list = entities.get('technologies', [])
        tech = tech_list[0] if tech_list else None
        
        if tech_depth == "æ·±åº¦æŠ€æœ¯":
            base = "ä»æŠ€æœ¯å®ç°è§’åº¦çœ‹ï¼Œè¯¥æ–¹æ¡ˆé‡‡ç”¨äº†å¤šå±‚æ¬¡çš„ä¼˜åŒ–ç­–ç•¥ã€‚åœ¨ç®—æ³•è®¾è®¡ä¸Šï¼Œç ”ç©¶å›¢é˜Ÿæå‡ºäº†åˆ›æ–°çš„æ•°å­¦æ¨¡å‹ï¼Œé€šè¿‡ç†è®ºåˆ†æè¯æ˜äº†æ–¹æ³•çš„æ”¶æ•›æ€§å’Œæœ€ä¼˜æ€§"
            
            if tech:
                base += f"ã€‚å…·ä½“è€Œè¨€ï¼Œæ ¸å¿ƒæŠ€æœ¯åŸºäº{tech}æ¡†æ¶ï¼Œ"
            else:
                base += "ã€‚"
            
            base += "é€šè¿‡ç²¾å¿ƒè®¾è®¡çš„æŸå¤±å‡½æ•°å’Œæ­£åˆ™åŒ–é¡¹ï¼Œåœ¨ä¿è¯æ¨¡å‹è¡¨è¾¾èƒ½åŠ›çš„åŒæ—¶æœ‰æ•ˆæ§åˆ¶äº†è¿‡æ‹Ÿåˆé£é™©ã€‚åœ¨å·¥ç¨‹å®ç°å±‚é¢ï¼Œå›¢é˜Ÿé’ˆå¯¹å…³é”®è®¡ç®—æ¨¡å—è¿›è¡Œäº†æ·±åº¦ä¼˜åŒ–ï¼Œé€šè¿‡ç®—å­èåˆã€å†…å­˜æ± åŒ–å’Œå¹¶è¡Œè°ƒåº¦ç­‰æ‰‹æ®µï¼Œæ˜¾è‘—æå‡äº†è¿è¡Œæ•ˆç‡ã€‚æ­¤å¤–ï¼Œå®Œå–„çš„å·¥å…·é“¾å’Œå¯è§†åŒ–ç•Œé¢é™ä½äº†ä½¿ç”¨é—¨æ§›ï¼Œä¾¿äºç ”ç©¶è€…å¿«é€Ÿå¤ç°å’Œæ‰©å±•"
        
        elif tech_depth == "ä¸­ç­‰æŠ€æœ¯":
            base = "æ–¹æ¡ˆçš„æ ¸å¿ƒåœ¨äºå°†å¤šç§æˆç†ŸæŠ€æœ¯è¿›è¡Œæœ‰æœºæ•´åˆï¼Œå½¢æˆç³»ç»Ÿæ€§çš„è§£å†³æ–¹æ¡ˆã€‚åœ¨æ¨¡å‹å±‚é¢ï¼Œé‡‡ç”¨äº†ç»è¿‡éªŒè¯çš„æ¶æ„è®¾è®¡ï¼Œå¹¶é’ˆå¯¹ç‰¹å®šä»»åŠ¡è¿›è¡Œäº†å®šåˆ¶åŒ–è°ƒæ•´"
            
            if 'ç«¯ä¾§' in ''.join(paragraphs[:2]).lower():
                base += "ã€‚é’ˆå¯¹ç«¯ä¾§éƒ¨ç½²åœºæ™¯ï¼Œå›¢é˜Ÿé‡ç‚¹ä¼˜åŒ–äº†æ¨¡å‹çš„æ¨ç†æµç¨‹ï¼Œé€šè¿‡é‡åŒ–å’Œå‰ªææŠ€æœ¯å¤§å¹…é™ä½äº†è®¡ç®—å¤æ‚åº¦å’Œå†…å­˜å ç”¨"
            
            base += "ã€‚åœ¨è®­ç»ƒç­–ç•¥ä¸Šï¼Œç»“åˆäº†æ•°æ®å¢å¼ºã€å­¦ä¹ ç‡è°ƒåº¦å’Œæ—©åœç­‰å¸¸ç”¨æŠ€å·§ï¼Œç¡®ä¿æ¨¡å‹èƒ½å¤Ÿç¨³å®šæ”¶æ•›åˆ°ç†æƒ³çŠ¶æ€ã€‚å·¥ç¨‹å®ç°æ³¨é‡ä»£ç çš„æ¨¡å—åŒ–å’Œå¯ç»´æŠ¤æ€§ï¼Œæ¸…æ™°çš„æ¥å£è®¾è®¡å’Œè¯¦å®çš„æ–‡æ¡£æ”¯æŒï¼Œä½¿å¾—æ–¹æ¡ˆæ˜“äºç†è§£å’Œéƒ¨ç½²"
        
        else:  # åº”ç”¨ä»‹ç»
            base = "è¯¥æ–¹æ¡ˆæ³¨é‡å®ç”¨æ€§å’Œæ˜“ç”¨æ€§ï¼Œé€šè¿‡ç®€æ´çš„è®¾è®¡ç†å¿µå’Œç¨³å®šçš„æ€§èƒ½è¡¨ç°ï¼Œä¸ºç”¨æˆ·æä¾›äº†å¼€ç®±å³ç”¨çš„è§£å†³æ–¹æ¡ˆã€‚ç³»ç»Ÿé‡‡ç”¨äº†ä¸»æµçš„æŠ€æœ¯æ ˆï¼Œä¿è¯äº†è‰¯å¥½çš„å…¼å®¹æ€§å’Œå¯æ‰©å±•æ€§"
            
            if category == 'è¡Œä¸šåŠ¨æ€':
                base += "ã€‚äº§å“é›†æˆäº†ç»è¿‡å……åˆ†éªŒè¯çš„AIèƒ½åŠ›ï¼Œé€šè¿‡å‹å¥½çš„äº¤äº’ç•Œé¢å’Œæµç•…çš„ä½¿ç”¨ä½“éªŒï¼Œè®©æŠ€æœ¯çœŸæ­£æœåŠ¡äºæ—¥å¸¸åº”ç”¨"
            
            base += "ã€‚åœ¨éƒ¨ç½²æ–¹é¢ï¼Œæä¾›äº†è¯¦ç»†çš„é…ç½®æŒ‡å—å’Œç¤ºä¾‹ä»£ç ï¼Œå¼€å‘è€…å¯ä»¥å¿«é€Ÿå®Œæˆé›†æˆå·¥ä½œã€‚åŒæ—¶ï¼Œæ´»è·ƒçš„ç¤¾åŒºæ”¯æŒå’ŒæŒç»­çš„ç‰ˆæœ¬è¿­ä»£ï¼Œç¡®ä¿äº†æ–¹æ¡ˆçš„é•¿æœŸå¯ç”¨æ€§"
        
        return base
    
    @staticmethod
    def _generate_results_section(analysis: dict, paragraphs: list) -> str:
        """ç”Ÿæˆå®éªŒç»“æœéƒ¨åˆ†"""
        metrics = analysis['metrics']
        category = analysis['category']
        
        base = "ä¸ºéªŒè¯æ–¹æ¡ˆçš„æœ‰æ•ˆæ€§ï¼Œç ”ç©¶å›¢é˜Ÿå¼€å±•äº†å…¨é¢çš„å®éªŒè¯„ä¼°"
        
        if metrics['performance']:
            perf_str = 'ã€'.join(metrics['performance'][:2])
            base += f"ã€‚åœ¨æ ‡å‡†åŸºå‡†æµ‹è¯•ä¸Šï¼Œæ–¹æ¡ˆå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œå…·ä½“è¡¨ç°ä¸º{perf_str}"
        
        if metrics['scale']:
            scale_str = metrics['scale'][0]
            base += f"ã€‚æ¨¡å‹è§„æ¨¡æ–¹é¢ï¼Œ{scale_str}ï¼Œ"
        
        if category == 'æ¨¡å‹ç®—æ³•':
            base += "ã€‚æ¶ˆèå®éªŒè¿›ä¸€æ­¥æ­ç¤ºäº†å„ä¸ªç»„ä»¶çš„è´¡çŒ®åº¦ï¼Œè¯æ˜äº†è®¾è®¡é€‰æ‹©çš„åˆç†æ€§ã€‚ä¸ç°æœ‰ä¸»æµæ–¹æ³•çš„å¯¹æ¯”æ˜¾ç¤ºï¼Œæœ¬æ–¹æ¡ˆåœ¨å¤šä¸ªè¯„ä¼°ç»´åº¦ä¸Šéƒ½å…·æœ‰æ˜æ˜¾ä¼˜åŠ¿ï¼Œç‰¹åˆ«æ˜¯åœ¨æ•ˆç‡å’Œç²¾åº¦çš„æƒè¡¡ä¸Šæ‰¾åˆ°äº†æ›´ä¼˜çš„è§£å†³æ–¹æ¡ˆ"
        elif category == 'å¹³å°åº•åº§':
            base += "ã€‚æ€§èƒ½æµ‹è¯•æ¶µç›–äº†å¤šç§ç¡¬ä»¶å¹³å°å’Œä½¿ç”¨åœºæ™¯ï¼Œç»“æœè¡¨æ˜ç³»ç»Ÿå…·æœ‰è‰¯å¥½çš„é€šç”¨æ€§å’Œç¨³å®šæ€§ã€‚ç”¨æˆ·åé¦ˆç§¯æï¼Œè®¤ä¸ºæ–°ç‰ˆæœ¬åœ¨æ˜“ç”¨æ€§å’ŒåŠŸèƒ½å®Œæ•´æ€§ä¸Šéƒ½æœ‰è´¨çš„é£è·ƒ"
        else:
            base += "ã€‚å®é™…åº”ç”¨æ•ˆæœè¶…å‡ºé¢„æœŸï¼Œåœ¨çœŸå®ä¸šåŠ¡åœºæ™¯ä¸­å±•ç°å‡ºå¼ºå¤§çš„é€‚åº”èƒ½åŠ›å’Œé²æ£’æ€§"
        
        return base
    
    @staticmethod
    def _generate_impact_section(impact: str, category: str, themes: list, entities: dict) -> str:
        """ç”Ÿæˆå½±å“å±•æœ›éƒ¨åˆ†"""
        
        if impact == "é‡å¤§çªç ´":
            base = "è¿™é¡¹å·¥ä½œçš„æ„ä¹‰è¿œè¶…æŠ€æœ¯æœ¬èº«ï¼Œå¯èƒ½å¼•å‘é¢†åŸŸç ”ç©¶èŒƒå¼çš„æ·±åˆ»å˜é©"
        elif impact == "æ˜¾è‘—è¿›å±•":
            base = "è¯¥ç ”ç©¶ä¸ºè§£å†³é•¿æœŸå­˜åœ¨çš„æŠ€æœ¯éš¾é¢˜æä¾›äº†æ–°çš„è§†è§’å’Œæ–¹æ³•"
        else:
            base = "å°½ç®¡å±äºæ¸è¿›å¼æ”¹è¿›ï¼Œä½†å·¥ä½œåœ¨å®ç”¨æ€§å’Œå¯è½åœ°æ€§ä¸Šå…·æœ‰é‡è¦ä»·å€¼"
        
        if category == 'æ¨¡å‹ç®—æ³•':
            base += "ã€‚ä»è¡Œä¸šå½±å“çœ‹ï¼Œä¼˜ç§€çš„ç®—æ³•åˆ›æ–°å¾€å¾€èƒ½å¤Ÿå‚¬ç”Ÿæ–°çš„åº”ç”¨åœºæ™¯ï¼Œæ¨åŠ¨AIæŠ€æœ¯å‘æ›´å¹¿é˜”çš„é¢†åŸŸæ‹“å±•ã€‚ç‰¹åˆ«æ˜¯åœ¨å½“å‰ç®—åŠ›æˆæœ¬é«˜ä¼ã€æ•ˆç‡éœ€æ±‚è¿«åˆ‡çš„èƒŒæ™¯ä¸‹ï¼Œè¿™ç±»èšç„¦äºä¼˜åŒ–å’Œå‹ç¼©çš„ç ”ç©¶å·¥ä½œæ˜¾å¾—å°¤ä¸ºé‡è¦"
        
        elif category == 'å¹³å°åº•åº§':
            base += "ã€‚åŸºç¡€è®¾æ–½çš„å®Œå–„å¯¹æ•´ä¸ªAIç”Ÿæ€å…·æœ‰ä¹˜æ•°æ•ˆåº”ï¼Œä¼˜ç§€çš„æ¡†æ¶å’Œå·¥å…·èƒ½å¤Ÿé™ä½æŠ€æœ¯é—¨æ§›ï¼Œè®©æ›´å¤šå¼€å‘è€…å‚ä¸åˆ°AIåº”ç”¨çš„åˆ›æ–°ä¸­æ¥ã€‚è¿™ç§åº•å±‚èƒ½åŠ›çš„æå‡ï¼Œæœ€ç»ˆå°†è½¬åŒ–ä¸ºä¸Šå±‚åº”ç”¨çš„ç¹è£"
        
        elif category == 'è¡Œä¸šåŠ¨æ€':
            comp_list = entities.get('companies', [])
            comp = comp_list[0].title() if comp_list else 'é¾™å¤´ä¼ä¸š'
            base += f"ã€‚{comp}çš„æˆ˜ç•¥é€‰æ‹©å¾€å¾€å…·æœ‰é£å‘æ ‡æ„ä¹‰ï¼Œå…¶åœ¨AIé¢†åŸŸçš„å¸ƒå±€å’ŒæŠ•å…¥åŠ›åº¦ï¼Œåæ˜ äº†è¡Œä¸šå¯¹æŠ€æœ¯æœªæ¥çš„é›†ä½“åˆ¤æ–­ã€‚éšç€è¶Šæ¥è¶Šå¤šçš„ä¼ä¸šåŠ å…¥ç«äº‰ï¼ŒAIæŠ€æœ¯çš„è¿›æ­¥å°†æŒç»­åŠ é€Ÿ"
        
        else:  # å¤§Vè®¿è°ˆ
            base += "ã€‚é¡¶å°–ä¸“å®¶çš„æ´è§å¸®åŠ©æˆ‘ä»¬ç«™åœ¨æ›´é«˜çš„è§†è§’å®¡è§†æŠ€æœ¯å‘å±•ï¼Œä»–ä»¬å¯¹å®‰å…¨æ€§ã€å¯æ§æ€§å’Œç¤¾ä¼šå½±å“çš„å…³æ³¨ï¼Œæé†’æ•´ä¸ªè¡Œä¸šåœ¨è¿½æ±‚è¿›æ­¥çš„åŒæ—¶å¿…é¡»ä¿æŒè­¦é†’å’Œç†æ€§"
        
        base += "ã€‚å±•æœ›æœªæ¥ï¼ŒAIæŠ€æœ¯å°†ç»§ç»­æ²¿ç€é«˜æ•ˆåŒ–ã€å®ç”¨åŒ–å’Œå®‰å…¨åŒ–çš„æ–¹å‘æ¼”è¿›ï¼Œè€Œæ¯ä¸€é¡¹æ‰å®çš„ç ”ç©¶å·¥ä½œéƒ½æ˜¯é€šå‘è¿™ä¸€ç›®æ ‡çš„é‡è¦é˜¶æ¢¯"
        
        return base

# ================= ğŸ“§ EML ç”Ÿæˆå™¨ =================

class EMLGenerator:
    """EMLé‚®ä»¶æŠ¥å‘Šç”Ÿæˆå™¨"""
    
    @staticmethod
    def generate_eml(articles: list, date_str: str) -> str:
        """ç”Ÿæˆå®Œæ•´EMLæŠ¥å‘Š"""
        
        # æŒ‰åˆ†ç±»æ’åº
        category_order = ["æ¨¡å‹ç®—æ³•", "å¹³å°åº•åº§", "è¡Œä¸šåŠ¨æ€", "å¤§Vè®¿è°ˆ"]
        articles_sorted = sorted(
            articles,
            key=lambda x: category_order.index(x.get('category', 'è¡Œä¸šåŠ¨æ€'))
        )
        
        # ç”Ÿæˆç›®å½•è¡¨æ ¼HTML
        toc_html = EMLGenerator._generate_toc_table(articles_sorted)
        
        # ç”Ÿæˆè¯¦æƒ…HTML
        details_html = EMLGenerator._generate_details_section(articles_sorted)
        
        # ç»„è£…å®Œæ•´HTML
        html_body = EMLGenerator._assemble_html(toc_html, details_html, date_str)
        
        # ç”ŸæˆEMLå¤´éƒ¨
        subject = f"åŒ—ç¾AIæ´å¯Ÿå¿«è®¯~{date_str}"
        subject_encoded = base64.b64encode(subject.encode('utf-8')).decode('ascii')
        
        now = datetime.now()
        # æ ¼å¼åŒ–æ—¥æœŸæ—¶é—´ï¼ˆRFC 2822æ ¼å¼ï¼‰
        date_formatted = now.strftime("%a, %d %b %Y %H:%M:%S") + " -0500"  # ESTæ—¶åŒº
        
        eml_content = f"""From: "åŒ—ç¾AIæ´å¯Ÿå¿«è®¯" <insight@moore-institute.ca>
To: subscriber@example.com
Subject: =?UTF-8?B?{subject_encoded}?=
Date: {date_formatted}
MIME-Version: 1.0
Content-Type: text/html; charset=UTF-8
Content-Transfer-Encoding: 8bit

{html_body}"""
        
        return eml_content
    
    @staticmethod
    def _generate_toc_table(articles: list) -> str:
        """ç”Ÿæˆç›®å½•è¡¨æ ¼"""
        rows = []
        category_counts = {}
        
        # ç»Ÿè®¡æ¯ä¸ªåˆ†ç±»çš„æ–‡ç« æ•°
        for article in articles:
            cat = article.get('category', 'è¡Œä¸šåŠ¨æ€')
            category_counts[cat] = category_counts.get(cat, 0) + 1
        
        current_category = None
        article_index = 1
        
        for article in articles:
            category = article.get('category', 'è¡Œä¸šåŠ¨æ€')
            title = article.get('chinese_title', 'æœªå‘½å')
            author = article.get('author', 'æœªçŸ¥')
            
            if category != current_category:
                # æ–°åˆ†ç±»ï¼Œéœ€è¦åˆå¹¶å•å…ƒæ ¼
                rowspan = category_counts[category]
                rows.append(f'''
                <tr>
                    <td class="category-cell" rowspan="{rowspan}">{category}</td>
                    <td><a href="#article-{article_index}"><strong>{title}</strong></a></td>
                    <td>{author}</td>
                </tr>''')
                current_category = category
            else:
                # åŒä¸€åˆ†ç±»
                rows.append(f'''
                <tr>
                    <td><a href="#article-{article_index}"><strong>{title}</strong></a></td>
                    <td>{author}</td>
                </tr>''')
            
            article_index += 1
        
        return '\n'.join(rows)
    
    @staticmethod
    def _generate_details_section(articles: list) -> str:
        """ç”Ÿæˆè¯¦æƒ…éƒ¨åˆ†"""
        details = []
        article_index = 1
        
        for article in articles:
            title = article.get('chinese_title', 'æœªå‘½å')
            category = article.get('category', 'è¡Œä¸šåŠ¨æ€')
            author = article.get('author', 'æœªçŸ¥')
            key_points = article.get('key_points', {})
            detail = article.get('detailed_explanation', '')
            
            article_html = f'''
        <div class="article-box">
            <a id="article-{article_index}" name="article-{article_index}"></a>
            <div class="article-title">{title}</div>
            <div class="article-meta">åˆ†ç±»: {category} | æœºæ„: {author}</div>
            
            <div class="summary-section">
                <div class="summary-title">ğŸ“Œ å†…å®¹ç®€è¿°</div>
                <div class="summary-content">{key_points.get('content_brief', '')}</div>
            </div>
            
            <div class="summary-section">
                <div class="summary-title">ğŸ’¡ å…³é”®åˆ›æ–°</div>
                <div class="summary-content">{key_points.get('key_innovation', '')}</div>
            </div>
            
            <div class="summary-section">
                <div class="summary-title">ğŸ¯ æ´å¯Ÿå¯ç¤º</div>
                <div class="summary-content">{key_points.get('insight', '')}</div>
            </div>
            
            <div class="detail-section">
                <strong>è¯¦ç»†è¯´æ˜ï¼š</strong><br><br>
                {detail}
            </div>
            
            <a href="#toc" class="back-button">â†‘ è¿”å›ç›®å½•</a>
        </div>'''
            
            details.append(article_html)
            article_index += 1
        
        return '\n'.join(details)
    
    @staticmethod
    def _assemble_html(toc_html: str, details_html: str, date_str: str) -> str:
        """ç»„è£…å®Œæ•´HTML"""
        
        html = f'''<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <style>
        body {{
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, "Noto Sans", sans-serif;
            line-height: 1.8;
            color: #333;
            max-width: 900px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
        }}
        .header {{
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 40px 30px;
            border-radius: 12px 12px 0 0;
            text-align: center;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        }}
        .header h1 {{
            margin: 0;
            font-size: 32px;
            font-weight: 700;
            letter-spacing: -0.5px;
        }}
        .header p {{
            margin: 15px 0 0 0;
            opacity: 0.95;
            font-size: 16px;
        }}
        .container {{
            background: white;
            padding: 40px 35px;
            border-radius: 0 0 12px 12px;
            box-shadow: 0 2px 12px rgba(0,0,0,0.08);
        }}
        h2 {{
            color: #667eea;
            border-bottom: 3px solid #667eea;
            padding-bottom: 12px;
            margin-top: 0;
            margin-bottom: 25px;
            font-size: 26px;
            font-weight: 600;
        }}
        .toc-table {{
            width: 100%;
            border-collapse: collapse;
            margin: 25px 0;
            box-shadow: 0 2px 8px rgba(0,0,0,0.06);
            border-radius: 8px;
            overflow: hidden;
        }}
        .toc-table th {{
            background-color: #667eea;
            color: white;
            padding: 16px 14px;
            text-align: left;
            font-weight: 600;
            font-size: 15px;
        }}
        .toc-table td {{
            padding: 14px;
            border-bottom: 1px solid #e8e8e8;
            font-size: 14px;
        }}
        .toc-table tr:last-child td {{
            border-bottom: none;
        }}
        .toc-table tr:hover {{
            background-color: #f8f9fe;
        }}
        .toc-table a {{
            color: #667eea;
            text-decoration: none;
            font-weight: 500;
            transition: color 0.2s;
        }}
        .toc-table a:hover {{
            color: #5568d3;
            text-decoration: underline;
        }}
        .category-cell {{
            background-color: #f0f4ff;
            font-weight: 600;
            color: #667eea;
            vertical-align: middle;
            text-align: center;
        }}
        .article-box {{
            border: 2px solid #e0e0e0;
            border-radius: 10px;
            padding: 30px;
            margin: 30px 0;
            background: linear-gradient(to bottom, #fafafa 0%, #ffffff 100%);
            box-shadow: 0 2px 8px rgba(0,0,0,0.04);
        }}
        .article-title {{
            font-size: 24px;
            font-weight: 700;
            color: #2c3e50;
            margin-bottom: 12px;
            line-height: 1.4;
        }}
        .article-meta {{
            color: #7f8c8d;
            font-size: 14px;
            margin-bottom: 20px;
            padding-bottom: 15px;
            border-bottom: 1px solid #eee;
        }}
        .summary-section {{
            background: white;
            padding: 18px;
            border-radius: 8px;
            margin: 18px 0;
            border-left: 4px solid #667eea;
            box-shadow: 0 1px 3px rgba(0,0,0,0.05);
        }}
        .summary-title {{
            font-weight: 600;
            color: #667eea;
            margin-bottom: 10px;
            font-size: 16px;
        }}
        .summary-content {{
            color: #555;
            line-height: 1.9;
            font-size: 15px;
            text-align: justify;
        }}
        .detail-section {{
            margin-top: 20px;
            padding: 20px;
            background: white;
            border-radius: 8px;
            text-align: justify;
            line-height: 1.9;
            color: #444;
            font-size: 15px;
            box-shadow: 0 1px 3px rgba(0,0,0,0.05);
        }}
        .detail-section strong {{
            color: #667eea;
            font-size: 16px;
        }}
        .back-button {{
            display: inline-block;
            margin-top: 20px;
            padding: 10px 20px;
            background-color: #667eea;
            color: white;
            text-decoration: none;
            border-radius: 6px;
            font-size: 14px;
            font-weight: 500;
            transition: background-color 0.3s;
        }}
        .back-button:hover {{
            background-color: #5568d3;
        }}
        .footer {{
            text-align: center;
            margin-top: 50px;
            padding-top: 25px;
            border-top: 2px solid #e0e0e0;
            color: #7f8c8d;
            font-size: 14px;
        }}
        .footer p {{
            margin: 8px 0;
        }}
        .footer strong {{
            color: #667eea;
            font-size: 16px;
        }}
    </style>
</head>
<body>
    <div class="header">
        <h1>ğŸ”¬ åŒ—ç¾AIæ´å¯Ÿå¿«è®¯</h1>
        <p>åŠ æ‹¿å¤§ç ”ç©¶é™¢æ‘©å°”ç ”ç©¶æ‰€ | {date_str}</p>
    </div>
    
    <div class="container">
        <h2 id="toc">ğŸ“‹ å†…å®¹é€Ÿè§ˆ</h2>
        
        <table class="toc-table">
            <thead>
                <tr>
                    <th width="15%">åˆ†ç±»</th>
                    <th width="60%">æ ‡é¢˜</th>
                    <th width="25%">æœºæ„</th>
                </tr>
            </thead>
            <tbody>
                {toc_html}
            </tbody>
        </table>
        
        <h2>ğŸ“° å†…å®¹è¯¦æƒ…</h2>
        
        {details_html}
        
        <div class="footer">
            <p><strong>åŠ æ‹¿å¤§ç ”ç©¶é™¢æ‘©å°”ç ”ç©¶æ‰€</strong></p>
            <p>Moore Institute of Canadian Research Academy</p>
            <p>ä¸“æ³¨äºAIæŠ€æœ¯æ´å¯Ÿä¸å‰æ²¿ç ”ç©¶</p>
            <p style="margin-top: 15px; font-size: 12px; color: #999;">
                æœ¬æŠ¥å‘Šç”±æ™ºèƒ½åˆ†æç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆ | å†…å®¹ä»…ä¾›å‚è€ƒ
            </p>
        </div>
    </div>
</body>
</html>'''
        
        return html

# ================= ğŸš€ ä¸»æµç¨‹ç¼–æ’ =================

def process_rss_to_eml(rss_file: str, output_dir: str = '.') -> str:
    """
    ä¸»æµç¨‹ï¼šä»RSSæ–‡ä»¶ç”ŸæˆEMLæŠ¥å‘Š
    
    Args:
        rss_file: RSS XMLæ–‡ä»¶è·¯å¾„
        output_dir: è¾“å‡ºç›®å½•
    
    Returns:
        ç”Ÿæˆçš„EMLæ–‡ä»¶è·¯å¾„
    """
    print("\n" + "="*70)
    print("ğŸš€ æ··åˆæ¶æ„ RSS æ™ºèƒ½åˆ†æç³»ç»Ÿ v4.0")
    print("="*70 + "\n")
    
    # 1. è§£æRSSæ–‡ä»¶ï¼Œæå–é“¾æ¥
    print("ğŸ“„ è§£æRSSæ–‡ä»¶...")
    try:
        import xml.etree.ElementTree as ET
        tree = ET.parse(rss_file)
        root = tree.getroot()
        
        links = []
        for item in root.findall('.//item'):
            link_elem = item.find('link')
            if link_elem is not None and link_elem.text:
                links.append(link_elem.text.strip())
        
        print(f"âœ… æ‰¾åˆ° {len(links)} ä¸ªé“¾æ¥\n")
    except Exception as e:
        print(f"âŒ RSSè§£æå¤±è´¥: {e}")
        return ""
    
    # 2. æ·±åº¦æŠ“å–å’Œåˆ†ææ¯ä¸ªé“¾æ¥
    articles = []
    
    for idx, url in enumerate(links, 1):
        print(f"[{idx}/{len(links)}] å¤„ç†é“¾æ¥...")
        
        # æ·±åº¦æŠ“å–
        article_data = DeepWebScraper.extract_article_content(url)
        
        if not article_data['success'] or article_data['word_count'] < 100:
            print("  âš ï¸ å†…å®¹ä¸è¶³ï¼Œè·³è¿‡\n")
            continue
        
        # è¯­ä¹‰åˆ†æ
        print("  ğŸ§  è¯­ä¹‰åˆ†æä¸­...")
        analysis = SemanticAnalyzerV4.analyze_content(article_data)
        
        # ç”Ÿæˆä¸­æ–‡æ ‡é¢˜
        chinese_title = TemplateEngine.generate_chinese_title(
            analysis, article_data['title']
        )
        print(f"  ğŸ“ æ ‡é¢˜: {chinese_title}")
        
        # ç”Ÿæˆä¸‰è¦ç‚¹
        key_points = TemplateEngine.generate_key_points(analysis, article_data)
        
        # ç”Ÿæˆè¯¦ç»†è¯´æ˜
        detailed_explanation = TemplateEngine.generate_detailed_explanation(
            analysis, article_data, key_points
        )
        
        # æ±‡æ€»
        articles.append({
            'url': url,
            'original_title': article_data['title'],
            'chinese_title': chinese_title,
            'category': analysis['category'],
            'author': article_data['metadata'].get('source', 'æœªçŸ¥'),
            'key_points': key_points,
            'detailed_explanation': detailed_explanation,
            'analysis': analysis
        })
        
        print(f"  âœ… å®Œæˆ [åˆ†ç±»: {analysis['category']}]\n")
    
    # 3. ç”ŸæˆEMLæŠ¥å‘Š
    print("="*70)
    print("ğŸ“§ ç”ŸæˆEMLæŠ¥å‘Š...")
    
    if not articles:
        print("âŒ æ²¡æœ‰æœ‰æ•ˆæ–‡ç« ï¼Œæ— æ³•ç”ŸæˆæŠ¥å‘Š")
        return ""
    
    date_str = datetime.now().strftime("%Y-%m-%d")
    eml_content = EMLGenerator.generate_eml(articles, date_str)
    
    # 4. ä¿å­˜æ–‡ä»¶
    output_file = f"{output_dir}/{date_str}.eml"
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(eml_content)
    
    print(f"âœ… æŠ¥å‘Šå·²ç”Ÿæˆ: {output_file}")
    print(f"ğŸ“Š å…±å¤„ç† {len(articles)} ç¯‡æ–‡ç« ")
    
    # ç»Ÿè®¡
    category_counts = {}
    for article in articles:
        cat = article['category']
        category_counts[cat] = category_counts.get(cat, 0) + 1
    
    print("\nğŸ“‚ åˆ†ç±»ç»Ÿè®¡:")
    for cat, count in sorted(category_counts.items()):
        print(f"  {cat}: {count}ç¯‡")
    
    print("\n" + "="*70)
    
    return output_file

# ================= ğŸ§ª æµ‹è¯•å…¥å£ =================

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1:
        rss_file = sys.argv[1]
        output_file = process_rss_to_eml(rss_file)
        print(f"\nâœ… å®Œæˆï¼è¾“å‡ºæ–‡ä»¶: {output_file}")
    else:
        print("ç”¨æ³•: python hybrid_rss_v4.py <rss_file.xml>")
        print("\nç³»ç»Ÿå·²å°±ç»ªï¼Œç­‰å¾…RSSæ–‡ä»¶è¾“å…¥...")
